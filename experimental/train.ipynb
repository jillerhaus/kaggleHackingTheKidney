{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdc8706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpu_devices:\n",
    "    for gpu_device in gpu_devices:\n",
    "        print(\"device available:\", gpu_device)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa141b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SM_FRAMEWORK=tf.keras\n",
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "tensorflow version: 2.6.0-dev20210407\n",
      "device available: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "device available: PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n",
      "WARNING:tensorflow:From C:\\Users\\apist\\anaconda3\\envs\\tfgpu2\\lib\\site-packages\\tensorflow\\python\\keras\\mixed_precision\\loss_scale.py:51: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
     ]
    }
   ],
   "source": [
    "%env SM_FRAMEWORK=tf.keras\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile as tiff\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as albu\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import *\n",
    "import segmentation_models as sm\n",
    "from segmentation_models import Unet, FPN\n",
    "from segmentation_models.losses import bce_jaccard_loss\n",
    "print(\"tensorflow version:\", tf.__version__)\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpu_devices:\n",
    "    for gpu_device in gpu_devices:\n",
    "        print(\"device available:\", gpu_device)\n",
    "policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "tf.keras.mixed_precision.experimental.set_policy(policy)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df12d023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device available: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "device available: PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpu_devices:\n",
    "    for gpu_device in gpu_devices:\n",
    "        print(\"device available:\", gpu_device)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4efe0b21",
   "metadata": {},
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import os\n",
    "os.environ['TF_MIN_GPU_MULTIPROCESSOR_COUNT']='4'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62e320d6",
   "metadata": {},
   "source": [
    "#from tensorflow.keras import mixed_precision\n",
    "#policy = mixed_precision.Policy(\"mixed_float16\")\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "import tensorflow.keras.backend as K\n",
    "from segmentation_models import Unet, FPN\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpu_devices:\n",
    "    for gpu_device in gpu_devices:\n",
    "        print(\"device available:\" , gpu_device)\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "tf.keras.mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "numerous-delight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-9719cbce-a56b-1f7d-efd5-519baafcfaef)\n",
      "GPU 1: NVIDIA GeForce RTX 3090 (UUID: GPU-0b211566-f864-21f7-b80e-db06ced5fe0d)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb76e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VER = \"v09\"\n",
    "PARAMS = {\n",
    "    \"version\": VER,\n",
    "    \"folds\": 1,\n",
    "    \"img_size\": 256,\n",
    "    \"resize\": 4,\n",
    "    \"batch_size\" : 20,\n",
    "    \"epochs\": 30,\n",
    "    \"patience\": 20,\n",
    "    \"backbone\": \"efficientnetb2\",# efficientnetbX, resnet34/50, resnext50, seresnet34, seresnext\n",
    "    \"loss\": \"bce_dice\",\n",
    "    \"mirror\": False,\n",
    "    \"umodel\" : \"unet\",\n",
    "    \"bce_weight\": 1.,\n",
    "    \"shift\": True,\n",
    "    \"pseudo\":\"\",\n",
    "    \"lr\": 0.0002\n",
    "}\n",
    "DATA_PATH = \"../input/hubmap-kidney-segmentation\"\n",
    "\n",
    "\n",
    "IMGS_PATH = f\"{DATA_PATH}/tiles_r\"\n",
    "MASKS_PATH = f\"{DATA_PATH}/masks_r\"\n",
    "\n",
    "MDLS_PATH = f\"./models_{VER}\"\n",
    "if not os.path.exists(MDLS_PATH):\n",
    "    os.mkdir(MDLS_PATH)\n",
    "with open(f\"{MDLS_PATH}/params.json\", \"w\") as file:\n",
    "    json.dump(PARAMS,file)\n",
    "        \n",
    "\n",
    "if not PARAMS[\"mirror\"]:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    STRATEGY = tf.distribute.get_strategy()\n",
    "else:\n",
    "    STRATEGY = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dress-stereo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(PARAMS[\"pseudo\"] == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "constant-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_masks = pd.read_csv(f\"{DATA_PATH}/train.csv\").set_index(\"id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "organic-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc2mask(encs, shape):\n",
    "    img = np.zeros(shape[0] * shape[1])\n",
    "    for m, enc in enumerate(encs):\n",
    "        if isinstance(enc,np.float) and np.isnan(enc): continue\n",
    "        s = enc.split()\n",
    "        for i in range(len(s) // 2):\n",
    "            start = int(s[2 * i]) - 1\n",
    "            length = int(s[ 2 * i + 1])\n",
    "            img[start : start + length] = 1 + m\n",
    "        return img.reshape(shape).T\n",
    "\n",
    "def show_img_n_mask(df, img_num, resize):\n",
    "    img = tiff.imread(os.path.join(f'{DATA_PATH}/train', df.index[img_num] + '.tiff'))\n",
    "    if len(img.shape) == 5:\n",
    "        img = (np.transpose(img.squeeze(), (1,2,0)))\n",
    "    mask = enc2mask(df.iloc[img_num], (img.shape[1], img.shape[0]))\n",
    "    print(img.shape, mask.shape)\n",
    "    img = cv2.resize(img,\n",
    "                    (img.shape[1] // reize, img.shape[0] // resize),\n",
    "                     interpolation = cv2.INTER_NEAREST)\n",
    "    plt.figure(figsize = (8,8))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(mask, alpha= 0.4)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "electric-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenKid(Sequence):\n",
    "    \n",
    "    def __init__(self, imgs_path, msks_path, imgs_idxs, img_size, batch_size, mode):\n",
    "        self.imgs_path = imgs_path\n",
    "        self.msks_path = msks_path\n",
    "        self.imgs_idxs = imgs_idxs\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.imgs_idxs) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.imgs_idxs))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_size = min(self.batch_size, len(self.imgs_idxs) - index * self.batch_size)\n",
    "        X = np.zeros((batch_size, self.img_size, self.img_size, 3), dtype = np.float32)\n",
    "        imgs_batch = self.imgs_idxs[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        if self.mode == \"fit\":\n",
    "            y = np.zeros((batch_size, self.img_size, self.img_size), dtype = np.float32)\n",
    "            for i, img_idx in enumerate(imgs_batch):\n",
    "                X[i, ], y[i] = self.get_tile(img_idx)\n",
    "            return X,y\n",
    "        elif self.mode == \"predict\":\n",
    "            for i, img_idx in enumerate(imgs_batch):\n",
    "                X[i, ] = self.get_tile(img_idx)\n",
    "            return X\n",
    "        else:\n",
    "            raise AttributeError(\"Fit mode parameter error\")\n",
    "            \n",
    "    def get_tile(self, img_idx):\n",
    "        img_path = f\"{self.imgs_path}/{img_idx}.png\"\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"error loading image: {image_path}\")\n",
    "        img = img.astype(np.float32) / 255\n",
    "        if self.mode == \"fit\":\n",
    "            msk_path = f\"{self.msks_path}/{img_idx}.png\"\n",
    "            msk = cv2.imread(msk_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if msk is None:\n",
    "                print(f\"error loading mask: {msk_path}\")\n",
    "            return img, msk\n",
    "        else:\n",
    "            return img\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "natural-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_idxs = [x.replace(\".png\", \"\") for x in os.listdir(IMGS_PATH) if \"png\" in x]\n",
    "train_datagen = DataGenKid(\n",
    "        imgs_path = IMGS_PATH,\n",
    "        msks_path = MASKS_PATH,\n",
    "        imgs_idxs = imgs_idxs,\n",
    "        img_size = PARAMS[\"img_size\"],\n",
    "        batch_size = PARAMS[\"batch_size\"],\n",
    "        mode = \"fit\"\n",
    ")\n",
    "\n",
    "val_datagen = DataGenKid(\n",
    "        imgs_path = IMGS_PATH,\n",
    "        msks_path = MASKS_PATH,\n",
    "        imgs_idxs = imgs_idxs,\n",
    "        img_size = PARAMS[\"img_size\"],\n",
    "        batch_size = PARAMS[\"batch_size\"],\n",
    "        mode = \"fit\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dried-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth = 1):\n",
    "    return (1 - dice_coef(y_true, y_pred))\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return PARAMS[\"bce_weight\"] * binary_crossentropy(y_true, y_pred) + \\\n",
    "        (1 - PARAMS[\"bce_weight\"]) * dice_loss(y_true, y_pred)\n",
    "\n",
    "def get_model(backbone, input_shape, loss_type = \"bce_dice\", umodel = \"unet\", classes = 1, lr = .001):\n",
    "    with STRATEGY.scope():\n",
    "        if loss_type == \"bce_dice\":\n",
    "            loss = bce_dice_loss\n",
    "        \n",
    "        # TODO: Implement other bce_jaccard_loss\n",
    "            \n",
    "        else: \n",
    "            raise AttributeError(\"loss mode parameter error\")\n",
    "        \n",
    "        if umodel == \"unet\":\n",
    "            model = Unet(backbone_name = backbone, encoder_weights = \"imagenet\",\n",
    "                        input_shape = input_shape, classes = classes, activation = \"sigmoid\")\n",
    "            \n",
    "        elif umodel == \"fpn\":\n",
    "            model = FPN(backbone_name = backbone, encoder_weights = \"imagemet\",\n",
    "                       input_shape = input_shape,\n",
    "                       classes = classes, activation = \"sigmoid\")\n",
    "        \n",
    "        else:\n",
    "            raise AttributeError(\"umodel mode parameter error\")\n",
    "            \n",
    "        model.compile(\n",
    "            optimizer = tfa.optimizers.Lookahead(\n",
    "                tf.keras.optimizers.Adam(learning_rate = lr),\n",
    "                sync_period = max(6, int(PARAMS[\"patience\"] / 4))\n",
    "            ),\n",
    "            loss = loss,\n",
    "            metrics = [dice_coef]\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-certificate",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "light-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(mparams, n_fold, train_datagen, val_datagen):\n",
    "    model = get_model(\n",
    "        mparams[\"backbone\"],\n",
    "        input_shape = (mparams[\"img_size\"], mparams[\"img_size\"], 3),\n",
    "        loss_type = mparams[\"loss\"],\n",
    "        umodel = mparams[\"umodel\"],\n",
    "        lr = mparams[\"lr\"]\n",
    "    )\n",
    "    checkpoint_path = f\"{MDLS_PATH}/model_{n_fold}.hdf5\"\n",
    "    earlystopper = EarlyStopping (\n",
    "        monitor = \"val_dice_coef\",\n",
    "        patience = mparams[\"patience\"],\n",
    "        verbose = 0,\n",
    "        restore_best_weights = True,\n",
    "        mode = \"max\"\n",
    "    )\n",
    "    lrreducer = ReduceLROnPlateau(\n",
    "        monitor = \"val_dice_coef\",\n",
    "        factor = .1,\n",
    "        patience = int(mparams[\"patience\"] / 2),\n",
    "        verbose = 0,\n",
    "        min_lr = 1e-7,\n",
    "        mode = \"max\"\n",
    "    )\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        monitor = \"val_dice_coef\",\n",
    "        verbose = 0,\n",
    "        save_best_only = True,\n",
    "        save_weights_only = True,\n",
    "        mode = \"max\"\n",
    "    )\n",
    "    callbacks = [earlystopper, checkpointer]\n",
    "    callbacks.append(lrreducer)\n",
    "    print(\"lr reduce on plateau\")\n",
    "    history = model.fit(\n",
    "        train_datagen,\n",
    "        validation_data = val_datagen,\n",
    "        callbacks = callbacks,\n",
    "        epochs = mparams[\"epochs\"],\n",
    "        verbose = 1\n",
    "    )\n",
    "    history_file = f\"{MDLS_PATH}/history_{n_fold}.json\"\n",
    "    dict_to_save = {}\n",
    "    for k,v in history.history.items():\n",
    "        dict_to_save.update({k: [np.format_float_positional(x) for x in history.history[k]]})\n",
    "    with open(history_file, \"w\") as file:\n",
    "        json.dump(dict_to_save, file)\n",
    "    model.load_weights(checkpoint_path)\n",
    "    return model,history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "delayed-debut",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f7af9caaa6f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPARAMS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_datagen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_datagen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-e9f8422c9108>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(mparams, n_fold, train_datagen, val_datagen)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mloss_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mumodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"umodel\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lr\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     )\n\u001b[0;32m      9\u001b[0m     \u001b[0mcheckpoint_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{MDLS_PATH}/model_{n_fold}.hdf5\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-e95a260c476d>\u001b[0m in \u001b[0;36mget_model\u001b[1;34m(backbone, input_shape, loss_type, umodel, classes, lr)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mumodel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"unet\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             model = Unet(backbone_name = backbone, encoder_weights = \"imagenet\",\n\u001b[1;32m---> 26\u001b[1;33m                         input_shape = input_shape, classes = classes, activation = \"sigmoid\")\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mumodel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"fpn\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu2\\lib\\site-packages\\segmentation_models\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_KERAS_MODELS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'utils'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_KERAS_UTILS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu2\\lib\\site-packages\\segmentation_models\\models\\unet.py\u001b[0m in \u001b[0;36mUnet\u001b[1;34m(backbone_name, input_shape, classes, activation, weights, encoder_weights, encoder_freeze, encoder_features, decoder_block_type, decoder_filters, decoder_use_batchnorm, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m     )\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu2\\lib\\site-packages\\segmentation_models\\backbones\\backbones_factory.py\u001b[0m in \u001b[0;36mget_backbone\u001b[1;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_backbone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mmodel_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu2\\lib\\site-packages\\classification_models\\models_factory.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mmodules_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mnew_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodules_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu2\\lib\\site-packages\\efficientnet\\model.py\u001b[0m in \u001b[0;36mEfficientNetB7\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[0;32m    596\u001b[0m                         \u001b[0minput_tensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                         \u001b[0mpooling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpooling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                         **kwargs)\n\u001b[0m\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu2\\lib\\site-packages\\efficientnet\\model.py\u001b[0m in \u001b[0;36mEfficientNet\u001b[1;34m(width_coefficient, depth_coefficient, default_resolution, dropout_rate, drop_connect_rate, depth_divisor, blocks_args, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[0;32m    472\u001b[0m                                             \u001b[0mcache_subdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m                                             file_hash=file_hash)\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2329\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[0;32m   2330\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2331\u001b[1;33m         \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2333\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu2\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    681\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayer_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m     \u001b[0mweight_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_attributes_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weight_names'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    684\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mweight_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m       \u001b[0mfiltered_layer_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu2\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_attributes_from_hdf5_group\u001b[1;34m(group, name)\u001b[0m\n\u001b[0;32m    859\u001b[0m     data = [\n\u001b[0;32m    860\u001b[0m         \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'decode'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m     ]\n\u001b[0;32m    863\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu2\\lib\\site-packages\\h5py\\_hl\\attrs.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mis_empty_dataspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu2\\lib\\site-packages\\h5py\\_hl\\base.py\u001b[0m in \u001b[0;36mis_empty_dataspace\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mis_empty_dataspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;34m\"\"\" Check if an object's dataspace is empty \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_simple_extent_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mh5s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNULL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, history = train_model(PARAMS, 1, train_datagen, val_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label = \"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label = \"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(history.history[\"dice_coef\"], label = \"dice_coeff\")\n",
    "plt.plot(history.history[\"val_dice_coef\"], label = \"val_dice_coef\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "best_epoch = np.argmax(history.history[\"val_dice_coef\"])\n",
    "best_loss = history.history[\"val_loss\"][best_epoch]\n",
    "best_dice_coef = history.history[\"val_dice_coef\"] [best_epoch]\n",
    "print(f\"\"\"\n",
    "best epoch: {best_epoch} \\n\n",
    "best loss: {best_loss} \\n\n",
    "best dice coeff: {best_dice_coef}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = PARAMS.copy()\n",
    "result[\"best_epoch\"] = np.mean([best_epoch])\n",
    "result[\"best_loss\"] = np.mean([best_loss])\n",
    "result[\"best_dice_coef\"] = np.mean([best_dice_coef])\n",
    "with open(f'{MDLS_PATH}/params.json', \"w\") as file:\n",
    "    json.dump(result,file)\n",
    "if not os.path.exists(\"results.csv\"):\n",
    "    df_save = pd.DataFrame(result, index = [0])\n",
    "    df_save.to_csv(\"results.csv\", sep= \"\\t\")\n",
    "else:\n",
    "    df_old = pd.read_csv(\"results.csv\", sep = \"\\t\")\n",
    "    df_save = pd.DataFrame(result, index= [df_old.index.max() + 1])\n",
    "    df_save = df_old.append(df_save, ignore_index = True)\n",
    "    df_save.to_csv(\"results.csv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"results.csv\", sep = \"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-diameter",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 1\n",
    "larger = 4\n",
    "test_models = []\n",
    "checkpoint_path = f\"{MDLS_PATH}/model_{n_fold}.hdf5\"\n",
    "print(checkpoint_path)\n",
    "model_lrg = get_model (\n",
    "    PARAMS[\"backbone\"],\n",
    "    input_shape = (PARAMS[\"img_size\"] * larger, PARAMS[\"img_size\"] * larger, 3),\n",
    "    loss_type = PARAMS[\"loss\"],\n",
    "    umodel = PARAMS[\"umodel\"]\n",
    ")\n",
    "model_lrg.load_weights(checkpoint_path) # or .set_weights(model.get_weights()) from smaller model\n",
    "test_models.append(model_lrg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5079e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = 0\n",
    "resize = PARAMS[\"resize\"]\n",
    "shft = 0.6\n",
    "wnd = PARAMS[\"img_size\"] * larger\n",
    "img = tiff.imread(os.path.join(f\"{DATA_PATH}/train\", df_masks.index[img_num] + \".tiff\"))\n",
    "if len(img.shape) == 5: img = np.transpose(img.squeeze(), (1,2,0))\n",
    "mask = enc2mask(df_masks.iloc[img_num], (img.shape[1], img.shape[0]))\n",
    "print(img.shape, mask.shape)\n",
    "imgs = cv2.resize(img,\n",
    "                 (img.shape[1] // resize, img.shape[0] // resize)\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d992814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
