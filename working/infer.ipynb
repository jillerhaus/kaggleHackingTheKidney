{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7853814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SM_FRAMEWORK=tf.keras\n"
     ]
    }
   ],
   "source": [
    "%env SM_FRAMEWORK=tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab8e4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt\n",
      "device available: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "system = os.name\n",
    "if system == 'posix':\n",
    "    KAGGLE = True\n",
    "else:\n",
    "    KAGGLE = False\n",
    "print(os.name)\n",
    "\n",
    "if KAGGLE:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpu_devices:\n",
    "    for gpu_device in gpu_devices:\n",
    "        print(\"device available:\", gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a8a9078",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KAGGLE:\n",
    "    !pip install ../input/keras-applications/Keras_Applications-1.0.8/ -f ./ --no-index\n",
    "    !pip install ../input/image-classifiers/image_classifiers-1.0.0/ -f ./ --no-index\n",
    "    !pip install ../input/efficientnet-1-0-0/efficientnet-1.0.0/ -f ./ --no-index\n",
    "    !pip install ../input/segmentationmodels/ -f ./ --no-index    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60cc2731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n",
      "tensorflow version: 2.4.1\n",
      "device available: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import shutil\n",
    "import numba\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tifffile as tiff\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import *\n",
    "import segmentation_models as sm\n",
    "from segmentation_models import Unet, FPN, Linknet\n",
    "from segmentation_models.losses import bce_jaccard_loss\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "print('tensorflow version:', tf.__version__)\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    for gpu_device in gpu_devices:\n",
    "        print('device available:', gpu_device)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "682ff4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>folds</th>\n",
       "      <th>img_size</th>\n",
       "      <th>resize</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>patience</th>\n",
       "      <th>backbone</th>\n",
       "      <th>loss</th>\n",
       "      <th>mirror</th>\n",
       "      <th>umodel</th>\n",
       "      <th>bce_weight</th>\n",
       "      <th>shift</th>\n",
       "      <th>pseudo</th>\n",
       "      <th>lr</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>best_loss</th>\n",
       "      <th>best_dice_coef</th>\n",
       "      <th>split</th>\n",
       "      <th>seed</th>\n",
       "      <th>bavg_epoch</th>\n",
       "      <th>bavg_loss</th>\n",
       "      <th>bavg_dice_coef</th>\n",
       "      <th>dice_by_folds</th>\n",
       "      <th>mixed_precision</th>\n",
       "      <th>aughard</th>\n",
       "      <th>norm</th>\n",
       "      <th>bnw</th>\n",
       "      <th>weights</th>\n",
       "      <th>triple</th>\n",
       "      <th>reduce_dims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb7</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>0.894248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb7</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kfold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.236562</td>\n",
       "      <td>0.454637</td>\n",
       "      <td>0.6554 0.4974 0.5797 0.0861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb7</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kfold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan 0.2318 0.3154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516637</td>\n",
       "      <td>0.077527</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>42.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.027320</td>\n",
       "      <td>0.777308</td>\n",
       "      <td>0.7773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>42.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.019676</td>\n",
       "      <td>0.884997</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb5</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kfold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.083721</td>\n",
       "      <td>0.637541</td>\n",
       "      <td>0.8200 0.8174 0.1290 0.7837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.033654</td>\n",
       "      <td>0.662921</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.073768</td>\n",
       "      <td>0.667674</td>\n",
       "      <td>0.6677</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>42.0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.025203</td>\n",
       "      <td>0.899880</td>\n",
       "      <td>0.8999</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.018537</td>\n",
       "      <td>0.875044</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>efficientnetb7</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kfold</td>\n",
       "      <td>69.0</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.017930</td>\n",
       "      <td>0.922658</td>\n",
       "      <td>0.9227</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb5</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kfold</td>\n",
       "      <td>69.0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.020173</td>\n",
       "      <td>0.885169</td>\n",
       "      <td>0.8852</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kfold</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.013263</td>\n",
       "      <td>0.874816</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>inceptionv3</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.012161</td>\n",
       "      <td>0.901803</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.911277</td>\n",
       "      <td>0.9113</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb1</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>0.011367</td>\n",
       "      <td>0.910720</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb7</td>\n",
       "      <td>bce_dice</td>\n",
       "      <td>False</td>\n",
       "      <td>unet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.009887</td>\n",
       "      <td>0.912130</td>\n",
       "      <td>0.9121</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>inceptionv3</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>0.012949</td>\n",
       "      <td>0.902273</td>\n",
       "      <td>0.9023</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb7</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.009965</td>\n",
       "      <td>0.912303</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>0.895391</td>\n",
       "      <td>0.8954</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.899069</td>\n",
       "      <td>0.8991</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>resnext50</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>0.922328</td>\n",
       "      <td>0.9223</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>fpn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.011716</td>\n",
       "      <td>0.898226</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>densenet201</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.012208</td>\n",
       "      <td>0.920322</td>\n",
       "      <td>0.9203</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>densenet121</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.012159</td>\n",
       "      <td>0.905066</td>\n",
       "      <td>0.9051</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.012303</td>\n",
       "      <td>0.892455</td>\n",
       "      <td>0.8925</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>resnext101</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.011064</td>\n",
       "      <td>0.927117</td>\n",
       "      <td>0.9271</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>0.018168</td>\n",
       "      <td>0.846635</td>\n",
       "      <td>0.8466</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.012189</td>\n",
       "      <td>0.892328</td>\n",
       "      <td>0.8923</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.012813</td>\n",
       "      <td>0.909781</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.029001</td>\n",
       "      <td>0.661627</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.029001</td>\n",
       "      <td>0.661627</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.031102</td>\n",
       "      <td>0.650727</td>\n",
       "      <td>0.6507</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.029677</td>\n",
       "      <td>0.666057</td>\n",
       "      <td>0.6661</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.029138</td>\n",
       "      <td>0.668435</td>\n",
       "      <td>0.6684</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb7</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kfold</td>\n",
       "      <td>69.0</td>\n",
       "      <td>129.400000</td>\n",
       "      <td>0.012331</td>\n",
       "      <td>0.905881</td>\n",
       "      <td>0.9072 0.9095 0.9040 0.8955 0.9132</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>113</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>densenet201</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kfold</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>0.010926</td>\n",
       "      <td>0.890535</td>\n",
       "      <td>0.9063 0.8748</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.012868</td>\n",
       "      <td>0.842104</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.011784</td>\n",
       "      <td>0.892494</td>\n",
       "      <td>0.8925</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>resnext101</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kfold</td>\n",
       "      <td>69.0</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan nan 0.9224 0.9285</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.012210</td>\n",
       "      <td>0.908255</td>\n",
       "      <td>0.9083</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.011454</td>\n",
       "      <td>0.907534</td>\n",
       "      <td>0.9075</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kfold</td>\n",
       "      <td>69.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.009831</td>\n",
       "      <td>0.854144</td>\n",
       "      <td>0.8541</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.009087</td>\n",
       "      <td>0.924909</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>efficientnetb0</td>\n",
       "      <td>bce_jaccard_loss</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dont</td>\n",
       "      <td>69.0</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.008998</td>\n",
       "      <td>0.917775</td>\n",
       "      <td>0.9178</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    version  folds  img_size  resize  batch_size  epochs  patience  \\\n",
       "0         6      1       256       1          20      30        20   \n",
       "1        13      4       256       1          32      40        20   \n",
       "2        14      4       256       4          32      40        20   \n",
       "3        22      1       256       4          64       1        20   \n",
       "4        24      1       256       4          32      20        20   \n",
       "5        25      1       256       4          32      20        20   \n",
       "6        17      4       256       4          16      30        20   \n",
       "7        27      1       256       4          32      20        10   \n",
       "8        31      1       256       4          32      20        10   \n",
       "9        26      1       256       4          32     100        10   \n",
       "10       36      1       256       4          40      20        10   \n",
       "11       37      1       256       4          40      20        20   \n",
       "12       38      1       256       4          32     100        10   \n",
       "13       40      1       256       4          16      50        20   \n",
       "14       41      1       256       4         128     100        20   \n",
       "15       42      1       256       4         128      50        20   \n",
       "16       45      1       256       4          64      50        20   \n",
       "17       47      1       256       4         128     100        20   \n",
       "18       49      1       256       4          40    1000        20   \n",
       "19       48      1       256       4          32     100        20   \n",
       "20       50      1       256       4          64    1000        20   \n",
       "21       55      1       256       4          32    1000        20   \n",
       "22       51      1       256       4          32     100        20   \n",
       "23       57      1       256       4          32    1000        20   \n",
       "24       59      1       256       4          32    1000        20   \n",
       "25       61      1       256       4         128    1000        20   \n",
       "26       65      1       256       4          32    1000        20   \n",
       "27       70      1       256       4          64    1000        20   \n",
       "28       72      1       256       4          32    1000        20   \n",
       "29       83      1       256       4          32    1000        20   \n",
       "30       84      1       256       4          32    1000        20   \n",
       "31       71      1       256       4          64    1000        20   \n",
       "32       89      1       256       4         128    1000        20   \n",
       "33       85      1       256       4          32    1000        20   \n",
       "34       94      1       256       4         128    1000        20   \n",
       "35       95      1       256       4         128      20        20   \n",
       "36       96      5       256       4         128      20        20   \n",
       "37       98      1       256       4         128      20        20   \n",
       "38       99      1       256       4         128      20        20   \n",
       "39      100      1       256       4         128      20        20   \n",
       "40      106      1       256       4          32    1000        20   \n",
       "41      105      1       256       4          32    1000        20   \n",
       "42      110      5       256       4         128    1000        20   \n",
       "43      113      2       256       4          32    1000        20   \n",
       "44      114      1       256       4          16    1000        20   \n",
       "45      115      1       256       4          32    1000        20   \n",
       "46      112      4       256       4          64    1000        20   \n",
       "47      116      1       256       4          64    1000        20   \n",
       "48      117      1       256       4          64    1000        20   \n",
       "49      127      1       512       4           8    1000        20   \n",
       "50      128      1       512       4          32    1000        20   \n",
       "51      129      1       512       4          32    1000        20   \n",
       "\n",
       "          backbone              loss  mirror umodel  bce_weight  shift  \\\n",
       "0   efficientnetb7          bce_dice   False   unet         1.0   True   \n",
       "1   efficientnetb7          bce_dice   False   unet         1.0   True   \n",
       "2   efficientnetb7          bce_dice   False   unet         1.0   True   \n",
       "3   efficientnetb0          bce_dice   False   unet         1.0   True   \n",
       "4   efficientnetb0          bce_dice   False   unet         1.0   True   \n",
       "5   efficientnetb0          bce_dice   False   unet         1.0   True   \n",
       "6   efficientnetb5          bce_dice   False   unet         1.0   True   \n",
       "7   efficientnetb0          bce_dice   False   unet         1.0   True   \n",
       "8   efficientnetb0          bce_dice   False   unet         1.0   True   \n",
       "9   efficientnetb0          bce_dice   False   unet         1.0   True   \n",
       "10  efficientnetb0          bce_dice   False   unet         1.0   True   \n",
       "11  efficientnetb0          bce_dice   False   unet         1.0   True   \n",
       "12  efficientnetb7          bce_dice   False   unet         1.0   True   \n",
       "13  efficientnetb5          bce_dice   False   unet         1.0   True   \n",
       "14  efficientnetb0          bce_dice   False   unet         1.0   True   \n",
       "15  efficientnetb0          bce_dice   False   unet         1.0   True   \n",
       "16     inceptionv3          bce_dice   False   unet         1.0   True   \n",
       "17  efficientnetb0          bce_dice   False   link         1.0   True   \n",
       "18  efficientnetb1  bce_jaccard_loss   False   link         1.0   True   \n",
       "19  efficientnetb7          bce_dice   False   unet         1.0   True   \n",
       "20     inceptionv3  bce_jaccard_loss   False   link         1.0   True   \n",
       "21        resnet50  bce_jaccard_loss   False   link         1.0   True   \n",
       "22  efficientnetb7  bce_jaccard_loss   False   link         1.0   True   \n",
       "23        resnet50  bce_jaccard_loss   False   link         1.0   True   \n",
       "24        resnet50  bce_jaccard_loss   False   link         1.0   True   \n",
       "25       resnext50  bce_jaccard_loss   False   link         1.0   True   \n",
       "26  efficientnetb0  bce_jaccard_loss   False    fpn         1.0   True   \n",
       "27     densenet201  bce_jaccard_loss   False   link         1.0   True   \n",
       "28     densenet121  bce_jaccard_loss   False   link         1.0   True   \n",
       "29  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "30  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "31      resnext101  bce_jaccard_loss   False   link         1.0   True   \n",
       "32  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "33  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "34  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "35  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "36  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "37  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "38  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "39  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "40  efficientnetb7  bce_jaccard_loss   False   link         1.0   True   \n",
       "41  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "42  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "43     densenet201  bce_jaccard_loss   False   link         1.0   True   \n",
       "44  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "45  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "46      resnext101  bce_jaccard_loss   False   link         1.0   True   \n",
       "47  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "48  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "49  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "50  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "51  efficientnetb0  bce_jaccard_loss   False   link         1.0   True   \n",
       "\n",
       "    pseudo      lr  best_epoch  best_loss  best_dice_coef  split  seed  \\\n",
       "0      NaN  0.0002        25.0   0.004156        0.894248    NaN   NaN   \n",
       "1      NaN  0.0002         NaN        NaN             NaN  kfold   NaN   \n",
       "2      NaN  0.0010         NaN        NaN             NaN  kfold   NaN   \n",
       "3      NaN  0.0001         NaN        NaN             NaN   dont   NaN   \n",
       "4      NaN  0.0001         NaN        NaN             NaN   dont  42.0   \n",
       "5      NaN  0.0001         NaN        NaN             NaN   dont  42.0   \n",
       "6      NaN  0.0002         NaN        NaN             NaN  kfold   NaN   \n",
       "7      NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "8      NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "9      NaN  0.0001         NaN        NaN             NaN   dont  42.0   \n",
       "10     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "11     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "12     NaN  0.0001         NaN        NaN             NaN  kfold  69.0   \n",
       "13     NaN  0.0001         NaN        NaN             NaN  kfold  69.0   \n",
       "14     NaN  0.0001         NaN        NaN             NaN  kfold  69.0   \n",
       "15     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "16     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "17     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "18     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "19     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "20     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "21     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "22     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "23     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "24     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "25     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "26     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "27     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "28     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "29     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "30     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "31     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "32     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "33     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "34     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "35     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "36     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "37     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "38     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "39     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "40     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "41     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "42     NaN  0.0001         NaN        NaN             NaN  kfold  69.0   \n",
       "43     NaN  0.0001         NaN        NaN             NaN  kfold  69.0   \n",
       "44     NaN  0.0001         NaN        NaN             NaN   dont  69.0   \n",
       "45     NaN  0.0005         NaN        NaN             NaN   dont  69.0   \n",
       "46     NaN  0.0001         NaN        NaN             NaN  kfold  69.0   \n",
       "47     NaN  0.0005         NaN        NaN             NaN   dont  69.0   \n",
       "48     NaN  0.0010         NaN        NaN             NaN   dont  69.0   \n",
       "49     NaN  0.0003         NaN        NaN             NaN  kfold  69.0   \n",
       "50     NaN  0.0005         NaN        NaN             NaN   dont  69.0   \n",
       "51     NaN  0.0005         NaN        NaN             NaN   dont  69.0   \n",
       "\n",
       "    bavg_epoch  bavg_loss  bavg_dice_coef                       dice_by_folds  \\\n",
       "0          NaN        NaN             NaN                                 NaN   \n",
       "1    15.500000   0.236562        0.454637         0.6554 0.4974 0.5797 0.0861   \n",
       "2    24.666667        NaN             NaN                   nan 0.2318 0.3154   \n",
       "3     0.000000   0.516637        0.077527                              0.0775   \n",
       "4    15.000000   0.027320        0.777308                              0.7773   \n",
       "5    19.000000   0.019676        0.884997                              0.8850   \n",
       "6    13.000000   0.083721        0.637541         0.8200 0.8174 0.1290 0.7837   \n",
       "7    16.000000   0.033654        0.662921                              0.6629   \n",
       "8    11.000000   0.073768        0.667674                              0.6677   \n",
       "9    46.000000   0.025203        0.899880                              0.8999   \n",
       "10         NaN        NaN             NaN                                 NaN   \n",
       "11   19.000000   0.018537        0.875044                              0.8750   \n",
       "12   52.000000   0.017930        0.922658                              0.9227   \n",
       "13   47.000000   0.020173        0.885169                              0.8852   \n",
       "14         NaN        NaN             NaN                                 NaN   \n",
       "15   49.000000   0.013263        0.874816                              0.8748   \n",
       "16   44.000000   0.012161        0.901803                              0.9018   \n",
       "17   97.000000   0.012695        0.911277                              0.9113   \n",
       "18   91.000000   0.011367        0.910720                              0.9107   \n",
       "19   58.000000   0.009887        0.912130                              0.9121   \n",
       "20   92.000000   0.012949        0.902273                              0.9023   \n",
       "21         NaN        NaN             NaN                                 NaN   \n",
       "22   90.000000   0.009965        0.912303                              0.9123   \n",
       "23   58.000000   0.011465        0.895391                              0.8954   \n",
       "24   78.000000   0.011445        0.899069                              0.8991   \n",
       "25  109.000000   0.011597        0.922328                              0.9223   \n",
       "26   58.000000   0.011716        0.898226                              0.8982   \n",
       "27   82.000000   0.012208        0.920322                              0.9203   \n",
       "28   78.000000   0.012159        0.905066                              0.9051   \n",
       "29         NaN        NaN             NaN                                 NaN   \n",
       "30  100.000000   0.012303        0.892455                              0.8925   \n",
       "31  156.000000   0.011064        0.927117                              0.9271   \n",
       "32  202.000000   0.018168        0.846635                              0.8466   \n",
       "33   78.000000   0.012189        0.892328                              0.8923   \n",
       "34  134.000000   0.012813        0.909781                              0.9098   \n",
       "35   19.000000   0.029001        0.661627                              0.6616   \n",
       "36   19.000000   0.029001        0.661627                              0.6616   \n",
       "37   19.000000   0.031102        0.650727                              0.6507   \n",
       "38   19.000000   0.029677        0.666057                              0.6661   \n",
       "39   19.000000   0.029138        0.668435                              0.6684   \n",
       "40         NaN        NaN             NaN                                 NaN   \n",
       "41         NaN        NaN             NaN                                 NaN   \n",
       "42  129.400000   0.012331        0.905881  0.9072 0.9095 0.9040 0.8955 0.9132   \n",
       "43   75.500000   0.010926        0.890535                       0.9063 0.8748   \n",
       "44   54.000000   0.012868        0.842104                              0.8421   \n",
       "45   56.000000   0.011784        0.892494                              0.8925   \n",
       "46   86.250000        NaN             NaN               nan nan 0.9224 0.9285   \n",
       "47   48.000000   0.012210        0.908255                              0.9083   \n",
       "48   59.000000   0.011454        0.907534                              0.9075   \n",
       "49   80.000000   0.009831        0.854144                              0.8541   \n",
       "50  104.000000   0.009087        0.924909                              0.9249   \n",
       "51   87.000000   0.008998        0.917775                              0.9178   \n",
       "\n",
       "   mixed_precision aughard   norm    bnw  weights triple reduce_dims  \n",
       "0              NaN     NaN    NaN    NaN      NaN    NaN         NaN  \n",
       "1              NaN     NaN    NaN    NaN      NaN    NaN         NaN  \n",
       "2              NaN     NaN    NaN    NaN      NaN    NaN         NaN  \n",
       "3              NaN     NaN    NaN    NaN      NaN    NaN         NaN  \n",
       "4              NaN     NaN    NaN    NaN      NaN    NaN         NaN  \n",
       "5            False     NaN    NaN    NaN      NaN    NaN         NaN  \n",
       "6              NaN     NaN    NaN    NaN      NaN    NaN         NaN  \n",
       "7             True     NaN    NaN    NaN      NaN    NaN         NaN  \n",
       "8             True     NaN    NaN    NaN      NaN    NaN         NaN  \n",
       "9            False     NaN    NaN    NaN      NaN    NaN         NaN  \n",
       "10            True   False    NaN    NaN      NaN    NaN         NaN  \n",
       "11            True   False    NaN    NaN      NaN    NaN         NaN  \n",
       "12            True   False    NaN    NaN      NaN    NaN         NaN  \n",
       "13            True   False    NaN    NaN      NaN    NaN         NaN  \n",
       "14            True   False    NaN    NaN      NaN    NaN         NaN  \n",
       "15            True    True    NaN    NaN      NaN    NaN         NaN  \n",
       "16            True    True    NaN    NaN      NaN    NaN         NaN  \n",
       "17            True    True    NaN    NaN      NaN    NaN         NaN  \n",
       "18            True    True    NaN    NaN      NaN    NaN         NaN  \n",
       "19            True    True    NaN    NaN      NaN    NaN         NaN  \n",
       "20            True    True    NaN    NaN      NaN    NaN         NaN  \n",
       "21            True    True    NaN    NaN      NaN    NaN         NaN  \n",
       "22            True    True    NaN    NaN      NaN    NaN         NaN  \n",
       "23            True    True    NaN    NaN      NaN    NaN         NaN  \n",
       "24            True    True    NaN    NaN      NaN    NaN         NaN  \n",
       "25            True    True    NaN    NaN      NaN    NaN         NaN  \n",
       "26            True    True    NaN    NaN      NaN    NaN         NaN  \n",
       "27            True    True    NaN    NaN      NaN    NaN         NaN  \n",
       "28            True    True    NaN    NaN      NaN    NaN         NaN  \n",
       "29            True    True  False  False      NaN    NaN         NaN  \n",
       "30            True    True   True   True      NaN    NaN         NaN  \n",
       "31            True    True    NaN    NaN      NaN    NaN         NaN  \n",
       "32            True    True   True   True      NaN    NaN         NaN  \n",
       "33            True    True   True   True      NaN    NaN         NaN  \n",
       "34            True    True   True   True      NaN   True         NaN  \n",
       "35            True    True   True   True      NaN   True         NaN  \n",
       "36            True    True   True   True      NaN   True        True  \n",
       "37            True    True   True   True      NaN   True       False  \n",
       "38            True    True  False  False      NaN  False       False  \n",
       "39            True    True  False  False      NaN  False       False  \n",
       "40            True    True   True   True      NaN   True        True  \n",
       "41            True    True   True   True      NaN   True        True  \n",
       "42            True    True   True   True      NaN   True       False  \n",
       "43            True    True   True   True      NaN   True       False  \n",
       "44            True    True   True   True      NaN   True       False  \n",
       "45            True    True   True   True      NaN   True       False  \n",
       "46            True    True   True   True      NaN   True       False  \n",
       "47            True    True   True   True      NaN   True       False  \n",
       "48            True    True   True   True      NaN   True       False  \n",
       "49            True    True   True   True      NaN   True        True  \n",
       "50            True    True   True   True      NaN   True       False  \n",
       "51            True    True   True   True      NaN   True       False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not KAGGLE:\n",
    "    res = pd.read_csv(\"../models/results.csv\", index_col = 0)\n",
    "else: res = 0\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd003a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False\n",
    "PLT_RAW = True\n",
    "if KAGGLE:\n",
    "    TEST = True\n",
    "    PLT_RAW = False\n",
    "\n",
    "VERS = [105]\n",
    "THRESHOLD = [0.43]\n",
    "WEIGHTS = [1]\n",
    "CONSENSUS = 0.32\n",
    "USE_FOLDS = [[0]]\n",
    "DATA_PATH = f\"../input/hubmap-kidney-segmentation\"\n",
    "if KAGGLE:\n",
    "    MDLS_PATH = \"../input/kidneymodel\"\n",
    "else:\n",
    "    MDLS_PATH = \"../models\"\n",
    "\n",
    "PAR_DICT = {}\n",
    "\n",
    "for VER in VERS:\n",
    "    MDL_PATH = f\"{MDLS_PATH}/models_v{VER:03}\"\n",
    "    PAR_DICT[VER] = {\"MDL_PATH\": MDL_PATH}\n",
    "SUB_PATH = f\"{DATA_PATH}/test\" if TEST else f\"{DATA_PATH}/train\"\n",
    "IDNT = rasterio.Affine(1, 0, 0, 0, 1, 0)\n",
    "EXPAND = 4\n",
    "MIN_OVERLAP = 256\n",
    "STRATEGY = tf.distribute.get_strategy()\n",
    "TTAS = [0, 1, 2, 3]\n",
    "\n",
    "VOTERS = 1\n",
    "TARGET_IMG = 'afa5e80ztu98.tiff'\n",
    "start_time = time.time()\n",
    "Y_SHFT = -40\n",
    "X_SHFT = -24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16b4fc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded params: {'version': 105, 'folds': 1, 'img_size': 256, 'resize': 4, 'batch_size': 32, 'epochs': 1000, 'patience': 20, 'backbone': 'efficientnetb0', 'loss': 'bce_jaccard_loss', 'mirror': False, 'umodel': 'link', 'bce_weight': 1.0, 'shift': True, 'pseudo': '', 'lr': 0.0001, 'split': 'dont', 'seed': 69, 'mixed_precision': True, 'aughard': True, 'norm': True, 'bnw': True, 'triple': True, 'reduce_dims': True, 'bavg_epoch': nan, 'bavg_loss': nan, 'bavg_dice_coef': nan, 'dice_by_folds': ''}\n"
     ]
    }
   ],
   "source": [
    "for VER in VERS:\n",
    "    with open(f\"{PAR_DICT[VER]['MDL_PATH']}/params.json\") as file:\n",
    "        PARAMS = json.load(file)\n",
    "        PAR_DICT[VER][\"PARAMS\"] = PARAMS\n",
    "    print(f\"loaded params: {PARAMS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8864a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc2mask(encs, shape):\n",
    "    img = np.zeros(shape[0] * shape[1], dtype = np.uint8)\n",
    "    for m, enc in enumerate(encs):\n",
    "        if isinstance(enc, np.float) and np.isnan(enc): continue\n",
    "        s = enc.split()\n",
    "        for i in range(len(s) // 2):\n",
    "            start = int(s[2 * i]) - 1\n",
    "            length = int(s[2 * i + 1])\n",
    "            img[start : start + length] = 1 + m\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def rle_encode_less_memory(img):\n",
    "    pixels = img.T.flatten()\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return \" \".join(str(x) for x in runs)\n",
    "\n",
    "def global_shift_mask(maskpred1, y_shift, x_shift):\n",
    "    \"\"\"\n",
    "    applies a global shift to a mask by padding\n",
    "    one side and cropping from the other\n",
    "    \"\"\"\n",
    "    if y_shift < 0 and x_shift >= 0:\n",
    "        maskpred2 = np.pad(maskpred1, [(0,abs(y_shift)), (abs(x_shift), 0)], mode = \"constant\", constant_values=0)\n",
    "        maskpred3 = maskpred2[abs(y_shift):, :maskpred1.shape[1]]\n",
    "    elif y_shift >= 0 and x_shift < 0:\n",
    "        maskpred2 = np.pad(maskpred1, [(abs(y_shift),0), (0, abs(x_shift))], mode = \"constant\", constant_values=0)\n",
    "        maskpred3 = maskpred2[:maskpred1.shape[0], abs(x_shift):]\n",
    "    elif y_shift >= 0 and x_shift >= 0:\n",
    "        maskpred2 = np.pad(maskpred1, [(abs(y_shift),0), (abs(x_shift), 0)], mode = \"constant\", constant_values=0)\n",
    "        maskpred3 = maskpred2[:maskpred1.shape[0], :maskpred1.shape[1]]\n",
    "    elif y_shift < 0 and x_shift < 0:\n",
    "        maskpred2 = np.pad(maskpred1, [(0, abs(y_shift)), (0, abs(x_shift))], mode = \"constant\", constant_values=0)\n",
    "        maskpred3 = maskpred2[abs(y_shift):, abs(x_shift):]\n",
    "    return maskpred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7edd640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth = 1):\n",
    "    return (1 - dice_coef(y_true, y_pred, smooth))\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return params[\"bce_weight\"] * binary_crossentropy(y_true, y_pred) + \\\n",
    "        (1 - params[\"bce_weight\"]) * dice_loss(y_true, y_pred)\n",
    "\n",
    "def get_model(backbone, input_shape, loss_type = \"bce_dice\",\n",
    "              umodel = \"unet\", classes = 1, lr = 0.001):\n",
    "    if backbone == \"efficientnetb0\":\n",
    "        weights = f\"{MDLS_PATH}/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\"\n",
    "\n",
    "    elif backbone == \"efficientnetb1\":\n",
    "        weights = f\"{MDLS_PATH}/efficientnet-b1_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\"\n",
    "        \n",
    "    elif backbone == \"efficientnetb2\":\n",
    "        weights = f\"{MDLS_PATH}/efficientnet-b2_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\"\n",
    "        \n",
    "    elif backbone == \"efficientnetb7\":\n",
    "        weights = f\"{MDLS_PATH}/efficientnet-b7_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\"\n",
    "        \n",
    "    elif backbone == \"inceptionv3\":\n",
    "        weights = f\"{MDLS_PATH}/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "        \n",
    "    elif backbone == \"resnext50\":\n",
    "        weights = f\"{MDLS_PATH}/resnext50_imagenet_1000_no_top.h5\"\n",
    "    \n",
    "    elif backbone == \"resnet50\":\n",
    "        weights = f\"{MDLS_PATH}/resnet50_imagenet_1000_no_top.h5\"\n",
    "    \n",
    "    elif backbone == \"seresnet50\":\n",
    "        weights = f\"{MDLS_PATH}/seresnet50_imagenet_1000_no_top.h5\"\n",
    "        \n",
    "    elif backbone == \"densenet201\":\n",
    "        weights = f\"{MDLS_PATH}/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "        \n",
    "    elif backbone == \"resnext101\":\n",
    "        weights = f\"{MDLS_PATH}/resnext101_imagenet_1000_no_top.h5\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        raise AttributeError(\"backbone unknown\")\n",
    "    if not KAGGLE:\n",
    "        weights = \"imagenet\"\n",
    "    with STRATEGY.scope():\n",
    "        if loss_type == \"bce_dice\":\n",
    "            loss = bce_dice_loss\n",
    "            \n",
    "        elif loss_type == \"bce_jaccard_loss\":\n",
    "            loss = bce_jaccard_loss\n",
    "            \n",
    "        else:\n",
    "            raise AttributeError(\"loss mode parameter error\")\n",
    "        if umodel == \"unet\":\n",
    "            model = Unet(backbone_name = backbone, encoder_weights = weights,\n",
    "                         input_shape = input_shape,\n",
    "                         classes = classes, activation = \"sigmoid\")\n",
    "        elif umodel == \"fpn\":\n",
    "            model = FPN(backbone_name = backbone, encoder_weights = weights,\n",
    "                        input_shape = input_shape,\n",
    "                        classes = classes, activation = \"sigmoid\")\n",
    "            \n",
    "        elif umodel == \"link\":\n",
    "            model = Linknet(backbone_name = backbone, encoder_weights = weights,\n",
    "                            input_shape = input_shape,\n",
    "                            classes = classes, activation = \"sigmoid\")\n",
    "            \n",
    "        else:\n",
    "            raise AttributeError(\"umodel mode parameter error\")\n",
    "        model.compile(\n",
    "            optimizer = tfa.optimizers.Lookahead(\n",
    "                tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "            ),\n",
    "            loss = loss,\n",
    "            metrics = [dice_coef]\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "861ccf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(shape, window = 256, min_overlap = 32):\n",
    "    x, y = shape\n",
    "    nx = x // (window - min_overlap) + 1\n",
    "    x1 = np.linspace(0, x, num = nx, endpoint = False, dtype = np.int64)\n",
    "    x1[-1] = x - window\n",
    "    x2 = (x1 + window).clip(0, x)\n",
    "    ny = y // (window - min_overlap) + 1\n",
    "    y1 = np.linspace(0, y, num = ny, endpoint = False, dtype = np.int64)\n",
    "    y1[-1] = y - window\n",
    "    y2 = (y1 + window).clip(0, y)\n",
    "    slices = np.zeros((nx, ny, 4), dtype = np.int64)\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            slices[i, j] = x1[i], x2[i], y1[j], y2[j]\n",
    "    return slices.reshape(nx * ny, 4)\n",
    "\n",
    "def flip(img, axis = 0):\n",
    "    if axis == 1:\n",
    "        return img[::-1, :, ]\n",
    "    elif axis == 2:\n",
    "        return img[:, ::-1, ]\n",
    "    elif axis == 3:\n",
    "        return img[::-1, ::-1, ]\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d746b4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_img(im):\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "    im = im * (255 / im.max())\n",
    "    im[im > 255] = 255\n",
    "    im = np.round(im).astype(np.uint8)\n",
    "    return im\n",
    "\n",
    "def triple_dims(im):\n",
    "    im = np.transpose(np.array([im,im,im]), (1, 2, 0))\n",
    "    return im\n",
    "\n",
    "subsets = [[0],[1],[2],[0,1],[0,2],[1,2],[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aa14589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images idxs: ['0486052bb.tiff', '095bf7a1f.tiff', '1e2425f28.tiff', '26dc41664.tiff', '2f6ecfcdf.tiff', '4ef6695ce.tiff', '54f2eec69.tiff', '8242609fa.tiff', 'aaa6a05cc.tiff', 'afa5e8098.tiff', 'b2dc8411c.tiff', 'b9a3865fc.tiff', 'c68fe75ea.tiff', 'cb2d976f4.tiff', 'e79de561c.tiff']\n"
     ]
    }
   ],
   "source": [
    "img_files = [x for x in os.listdir(SUB_PATH) if \".tiff\" in x]\n",
    "print(f\"images idxs: {img_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6926ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_unique(ar):\n",
    "    uniques = np.unique(ar)\n",
    "    print(uniques)\n",
    "    for unique in uniques:\n",
    "        print(f\"{(pred == unique).sum() / (pred.shape[0] * pred.shape[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cb1858a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded: ../models/models_v105/model_0.hdf5\n",
      "-------------------- 0486052bb.tiff --------------------\n",
      "img shape:  (25784, 34937)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b95e432ad44dbd8bfc17d9edebf576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0486052bb.tiff:   0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img max 4 | voters: 1\n",
      "-------------------- 095bf7a1f.tiff --------------------\n",
      "img shape:  (38160, 39000)\n",
      "img file with subdatasets as channels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef11b8080414ea295c9391be1e9cde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "095bf7a1f.tiff:   0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function IteratorResourceDeleter.__del__ at 0x0000021D3B4BD798>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\apist\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 535, in __del__\n",
      "    handle=self._handle, deleter=self._deleter)\n",
      "  File \"C:\\Users\\apist\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 1263, in delete_iterator\n",
      "    _ctx, \"DeleteIterator\", name, handle, deleter)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b4913bf1cba9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     89\u001b[0m                             \u001b[0mim_red\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_red\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                             \u001b[0mim_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_red\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m                             \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m                             \u001b[0mpred_aug\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mTHRESH_FOLDS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "subm = {}\n",
    "models = []\n",
    "VER_FOLDS = []\n",
    "THRESH_FOLDS = []\n",
    "WEIGHTS_FOLDS = []\n",
    "if PLT_RAW:\n",
    "    complete_results = []\n",
    "tile_size = int(PARAMS[\"img_size\"] * EXPAND)\n",
    "for i, VER in enumerate(VERS):\n",
    "    PARAMS = PAR_DICT[VER][\"PARAMS\"]\n",
    "    MDL_PATH = PAR_DICT[VER][\"MDL_PATH\"]\n",
    "    for use_fold in USE_FOLDS[i]:\n",
    "        fold_path = (f\"{MDL_PATH}/model_{use_fold}.hdf5\")\n",
    "        checkpoint_path = fold_path\n",
    "        model = get_model(\n",
    "            PARAMS[\"backbone\"],\n",
    "            input_shape = (tile_size, tile_size, 3),\n",
    "            loss_type = PARAMS[\"loss\"],\n",
    "            umodel = PARAMS[\"umodel\"]\n",
    "        )\n",
    "        model.load_weights(checkpoint_path)\n",
    "        models.append(model)\n",
    "        VER_FOLDS.append(VER)\n",
    "        THRESH_FOLDS.append(THRESHOLD[i])\n",
    "        WEIGHTS_FOLDS.append(WEIGHTS[i])\n",
    "        print(\"model loaded:\", checkpoint_path)\n",
    "\n",
    "for i_img, img_file in enumerate(img_files):\n",
    "    print(\"-\" * 20, img_file, \"-\" * 20)\n",
    "    img_data = rasterio.open(os.path.join(SUB_PATH, img_file), transform=IDNT)\n",
    "    print(\"img shape: \", img_data.shape)\n",
    "    if img_data.count != 3:\n",
    "        print(\"img file with subdatasets as channels\")\n",
    "        layers = [rasterio.open(subd) for subd in img_data.subdatasets]\n",
    "    img_preds = np.zeros(img_data.shape, dtype=np.uint8)\n",
    "    if PLT_RAW:\n",
    "        img_preds_mdls_raw = {}\n",
    "        for VER in VERS:\n",
    "            img_preds_mdls_raw[VER] = np.zeros(img_data.shape, dtype = np.float32)\n",
    "    \n",
    "    tile_resized = int(tile_size * PARAMS[\"resize\"])\n",
    "    slices = make_grid(\n",
    "        img_data.shape,\n",
    "        window = tile_resized,\n",
    "        min_overlap = MIN_OVERLAP\n",
    "    )\n",
    "    \n",
    "    for (x1, x2, y1, y2) in tqdm(slices, desc = f\"{img_file}\"):\n",
    "        if img_data.count == 3: #normal\n",
    "            img = img_data.read(\n",
    "                [1, 2, 3],\n",
    "                window = Window.from_slices((x1, x2), (y1, y2))\n",
    "            )\n",
    "            img = np.moveaxis(img, 0, -1)\n",
    "        else: # with subdatasets/layers\n",
    "            img = np.zeros((tile_resized, tile_resized, 3), dtype = np.uint8)\n",
    "            for fl in range(3):\n",
    "                img[:, :, fl] = layers[fl].read(\n",
    "                    window = Window.from_slices((x1, x2), (y1, y2))\n",
    "                )\n",
    "        img = cv2.resize(img, (tile_size, tile_size))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        pred = np.zeros((tile_size, tile_size), dtype = np.float32)\n",
    "        if PLT_RAW:\n",
    "            pred_raw = {}\n",
    "            for VER in VERS:\n",
    "                pred_raw[VER] = np.zeros((tile_size, tile_size), dtype = np.float32)\n",
    "        i = 0\n",
    "        for model1 in models:\n",
    "            VER = VER_FOLDS[i]\n",
    "            img_cust = img\n",
    "            if \"norm\" in PAR_DICT[VER][\"PARAMS\"].keys():\n",
    "                if PAR_DICT[VER][\"PARAMS\"][\"norm\"]:\n",
    "                    img_cust = norm_img(img_cust)\n",
    "                    img_cust = triple_dims(img_cust)        \n",
    "            \n",
    "            for tta_mode in TTAS:\n",
    "                img_aug = flip(img_cust, axis = tta_mode)\n",
    "                img_aug = np.expand_dims(img_aug, 0)\n",
    "                img_aug = img_aug.astype(np.float32) / 255\n",
    "                pred_aug = np.zeros((tile_size, tile_size), dtype = np.float32)\n",
    "                if \"reduce_dims\" in PAR_DICT[VER][\"PARAMS\"].keys():\n",
    "                    if PAR_DICT[VER][\"PARAMS\"][\"reduce_dims\"]:\n",
    "                        im = np.transpose(img_aug[0], (2,0,1))\n",
    "                        for inds in subsets:\n",
    "                            im_red = im.copy()\n",
    "                            for j in inds:\n",
    "                                im_red[j] = 0\n",
    "                            im_red = np.transpose(im_red, (1, 2, 0))\n",
    "                            im_pred = np.expand_dims(im_red, 0)\n",
    "                            prediction = model1.predict(im_pred)\n",
    "                            pred_aug += np.squeeze(prediction > THRESH_FOLDS[i]) / len(models) / 7\n",
    "                    else:\n",
    "                        prediction = model1.predict(img_aug)\n",
    "                        pred_aug += np.squeeze(prediction > THRESH_FOLDS[i]).astype(np.float32) / len(models)\n",
    "                else:\n",
    "                    prediction = model1.predict(img_aug)                    \n",
    "                    pred_aug += np.squeeze(prediction > THRESH_FOLDS[i]) / len(models)\n",
    "                    \n",
    "                pred += flip(pred_aug, axis = tta_mode).astype(np.float32) / len(TTAS) * WEIGHTS_FOLDS[i]\n",
    "                \n",
    "                if PLT_RAW:\n",
    "                    pred_aug_raw = np.zeros((tile_size, tile_size), dtype = np.float32)\n",
    "                    pred_aug_raw += np.squeeze(prediction)\n",
    "                    pred_raw[VER] += flip(pred_aug_raw, axis = tta_mode) / len(TTAS)\n",
    "                \n",
    "            i += 1\n",
    "        pred = cv2.resize(pred, (tile_resized, tile_resized), interpolation = cv2.INTER_NEAREST)\n",
    "        \n",
    "        img_preds[x1:x2, y1:y2] = img_preds[x1:x2, y1:y2] + \\\n",
    "            (pred > (CONSENSUS * sum(WEIGHTS_FOLDS)/len(WEIGHTS_FOLDS))).astype(np.uint8)\n",
    "        if PLT_RAW:\n",
    "            for VER in VERS:\n",
    "                pred_raw[VER] = cv2.resize(pred_raw[VER], (tile_resized, tile_resized))\n",
    "                img_preds_mdls_raw[VER][x1: x2, y1: y2] = pred_raw[VER] /\\\n",
    "                     PAR_DICT[VER][\"PARAMS\"][\"folds\"]\n",
    "    del img, pred, img_aug, pred_aug; gc.collect()\n",
    "    print(\"img max\", np.max(img_preds), \"| voters:\", VOTERS)\n",
    "    if img_file == TARGET_IMG:\n",
    "        print(\"global shift\")\n",
    "        img_preds = (img_preds >= VOTERS).astype(np.uint8)\n",
    "        img_preds = global_shift_mask(img_preds, Y_SHFT, X_SHFT)\n",
    "    else:\n",
    "        img_preds = (img_preds >= VOTERS).astype(np.uint8)\n",
    "    rle_pred = rle_encode_less_memory(img_preds)\n",
    "    subm[i_img] = {\"id\": img_file.replace(\".tiff\", \"\"), \"predicted\": rle_pred}\n",
    "    if PLT_RAW:\n",
    "        #img_preds_mdls_raw[69420] = np.array([69,420])\n",
    "        #df = pd.DataFrame.from_dict(img_preds_mdls_raw, orient = \"index\")\n",
    "        complete_results.append(img_preds_mdls_raw)\n",
    "        #df = df[df.index != 69420]\n",
    "        #df.to_csv(f\"../models/temp/{img_file.replace('.tiff','')}.csv\")\n",
    "        #del df, img_preds_mdls_raw; gc.collect()\n",
    "        del img_preds_mdls_raw; gc.collect()\n",
    "    del img_preds, img_data, rle_pred; gc.collect()\n",
    "\n",
    "del model, models ; gc.collect()\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ed9b5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0486052bb</td>\n",
       "      <td>101727643 52 101753427 52 101779211 52 1018049...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                          predicted\n",
       "0  0486052bb  101727643 52 101753427 52 101779211 52 1018049..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = pd.DataFrame(subm).T\n",
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2d7ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af988995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_np(pred, true, k = 1):\n",
    "    intersection = np.sum(pred[true == k]) * 2\n",
    "    dice = intersection / (np.sum(pred) + np.sum(true))\n",
    "    return dice\n",
    "\n",
    "def get_dice(mask, mask_lrg, th = 1):\n",
    "    mask_pred = np.squeeze(mask_lrg >= th)\n",
    "    return dice_np(mask, mask_pred)\n",
    "    \n",
    "def get_best_th_dice(mask, mask_lrg, n=20, plot = False):\n",
    "    thresholds = np.linspace(0, 1, n)\n",
    "    dices = [get_dice(mask, mask_lrg, th) for th in thresholds]\n",
    "    n_max = np.argmax(dices)\n",
    "    if plot:\n",
    "        plt.plot(thresholds, dices)\n",
    "        plt.title(f\"th: {thresholds[n_max]:.2f} dice: {dices[n_max]:.2f}\")\n",
    "        plt.show()\n",
    "    return thresholds, dices, n_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8731d616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "0486052bb\n",
      "(25784, 34937, 3)\n",
      "(25784, 34937, 3)\n",
      "(25784, 34937)\n",
      "(25784, 34937)\n",
      "dice_coef: 0.9537084068586238\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhxElEQVR4nO3dfZBcV33m8e+vu6d7pntmNNOjkWxLwjJeCSNY2xtkk7AYTKDAZjcxVAFlw0LwQnmdxAm71BK7QhY2Re0WL0lVwtqO46UMFSrEyYIXDBG4qAovoRwTyyAbhGOvsMESNrI8PRppel66p/u3f9zbo9ZoRtOj6e57+87zqeqavi99+9zR6OnT555zrrk7IiLS+1JRF0BERNpDgS4ikhAKdBGRhFCgi4gkhAJdRCQhFOgiIgmhQJfTmNlOM3Mzy0Rdlk4ys6vN7EjT8kEzuzq6EomsnwJ9gzOzn5nZG9p4PDOzT5jZRPj4pJlZC6/7aPhB8oamdWc9Vvjh8y0zmzGzf1nPebj7y9z92+f6+laYWc7M7jGzE2b2SzP74Fn2NTP7sJk9E+5/r5kNL7Nf0cyOmdn3lqz/DTP7sZlNm9mDZranadtvmdkj4XGPhL/XTNP2nWa2z8wmw3LenvQP+KRQoEu73QS8BbgMuBT498B/OtsLzOxi4G3Ac2s81t8APwTGgA8DXzSz8fWeQAf9d2AXcCHwOuAPzOyaFfZ9D/Bu4N8CFwADwP9aZr9PAI83rzCzXcBfAzcDI8BXgfubQjkP/GdgM/BK4PXAf206xJ3A88D5wOXAa4HfafEcJUrurscGfQCfB+rALDAN/AGwE3Dgt4BngBeAD6/hmA8CNzUtvw94aJXXfB14M/Az4A2tHAvYDcwDQ03b/xG4eYX3GAA+B0wCPwE+BBxp2r743kAa+EPgp8BJ4BFgR7jtEuCbQAl4AnjHGn43vwDe2LT8MeDeFfb9IvChpuVXAXNAvmndrwH/BNwIfK9p/S3A3zctp8J/49ev8F4fBL7atPw48Oam5U8Bfxn136seqz9UQ9/A3P3dBKH9G+4+6O6fbNr8auAlBLW3j5jZSwHM7NVmdvwsh30Z8GjT8qPhumWZ2duBirvvW+OxXgY85e4nW3yvjwIXh483EXxgreSDwA0EHzLDwH8EZsysQBDmXwC2hPvcaWYvC8/lnWb22ArnOUpQ0271d2Pho3k5R1DDx8zSwB0E4b10/o7lXmvAy1d4r9cAB5uW/xy43szyZrYNuBb4xgqvlRhRoMtK/tjdZ939UYLguQzA3b/n7iNned0gMNW0PAUMLteObmaDwP8k+Pq/1mMt3dbYPrTCsd4B/A93L7n7YeDTZzmH9wN/5O5PeOBRd58gaPL5mbt/1t0X3P0HwJcImotw9y+4+6VnOZdGGVsp79eB94ft2ZuAW8P1+fDn7wPfd/dHlnntN4HXhhd+swTfNrJNr11kZjcCe4E/aVr9HYIPmhPAEWA/8OUVyikxokCXlfyy6fkMpwJpNdMEtdqGYWDa3ZebBe6Pgc+7+9PncKyl2xrbT7K8C4DDTcs/X2E/gB0EzS1LXQi80syONx7Au4DzznKshummMrZS3nsIrhF8m6D2/K1w/REzu4Ag0D+83Avd/V8IvoHcTnBdYjNBM9OR5v3M7C3Ax4Fr3f2FcF0KeAC4DyiErx0laKuXmFOgS7un2zxIWJsPXcbpX+ebvR74/bAnxS8JgvTvzKxRGz3bsQ4CLzazoRW2L/VcePyGF53lHA4TNM0st/477j7S9Bh0998+y7EAcPfJsAwt/W7cve7uH3X3ne6+PdzvF+HjSoILlj8Jf29/DlwZ/h7T4eu/6O4vd/cxguamC4GHG8cPL8b+b4Lmth81vXWR4Pd0u7vPh99MPkvQ/CRxF3Ujvh7RPoCHOP3C406CkM80rfs28P4Wj3czwUW1bQS14oOsfKFyjKB223gcBt4ODLZyrLDsfwL0A28FjgPjK7zXJwiaEkaB7cBjrHxR9EPh9l0Ebc+XhmUdIqjZvxvoCx9XAC9t8Xfz8aYyXEIQ8NessG+R4EPFgD3Ajxv/TgRt6c2/tw8A3wfOa3r9Kwgu7o4Dfwt8oWnbrwMTwGtWeO+ngNuADEEvmf8L/HXUf6t6tPA3FnUB9Ij4DwCuI7gwepyg69pZAx24iqDZY6XjGfBJgl4gpfC5NW0/CLxrhdcuhmqLx9oZlm2WoMfJG85SrjzwV+F5ttLL5Y+ApwmaRB4GtofbXgL8PXAsDMV/AC4Pt70LOHiWMuQImlJOAEeBDy7ZPg1cFT7fHZ7TDMGHyAfPctz30tTLJVz3vbDsJeAvgULTtm8BC+H7NR5fb9p+efh7nSTo5fR/gC1R/63qsfrDwn9AERHpcWpDFxFJCAW6iEhCKNBFRBJCgS4ikhCRzaC2efNm37lzZ1RvLyLSkx555JEX3H3ZSegiC/SdO3eyf//+qN5eRKQnmdmKo5zV5CIikhAKdBGRhFCgi4gkhAJdRCQhFOgiIgmhQBcRSQgFuohIQkTWD13iqVZ35hdqzFfrzIU/F+p1FurOQs2p1Z2FeuNn/dRyLfi5uC7ct+ZO3Z16OFVzvR48r7vj4c9Ty6ee1x1YbSbQM+9qd2oTkEkZ6bTRl0qRThmZtJFOnb6caTxfsm+uL0V/Jk1/X4r+vnT4SJHLpEmnVn5fkSgp0HuMuzNTqVGeX2B6foHyfC38uUC5snDq+XxtcV15vsZctcbcQp35ao35hTpz1RqVhfri8/mFOvMLNaq1+EynfJa8XjXrO6kvbfRn0uT6mgO/8QEQBn9fmoFl1p/6cDh920A2+LAYyAavG+gLnucyKZa5HavIshToEZir1piarZ56zFRPX56tcmLp8lw1COnKQsthls+mKeQyFLJBaOT6goAY6s8wPpQjlwlCpFHzbPwMaqepxf370qmgBrtYy21aXvx5Zi04lYJMKkXKwMxIGaTMSJlhqcbz4Kc1bWvsvx7up75NNL5BVJd8o6gu+TbRWK7Wgg+6+WqNuWrwgdf4QJxrWje/0Pw8+DlTWaBUXu41teBbxxqZcVrAN37296XJN4V/fzZNvi/NYH+GwVyGQi74OZjLMNifoZDNMNR/an02o9bWJFKgt0mt7kyU5zk6Nc/RE3McPTnH0RPzHJ069Xxiep6p2SrzC/WzHmsol2F4oI+RfB+bBvr4V1sGGe7vC/8zhiGdO/Uft5Bdui5NPpvZ0E0DZmGTSjrqkgTcnUqtzly16YNiocZs5czgn63UmK2Gj8oyy+HPyXKFX4TLc9Ua5fngeSuy6VQQ9Lk0g7k+BnNphvr7GOrPMBz+XFweaKwP1jW257NpfXuIGQV6i16YnufJoyf5xeRsENgnGsEdhPax6XlqS6pgZrB5MMfW4RzbRvq5dNsmNoUhvdJjqD9DJq3aU9KYWfDtJ5OGgb6Ovc9CrU65qUmu0QQ3PXf68snT1teYnq9y9MQch55f4MRclZNzC2f8PS+VThmDuQzDA5klf8dZNjVVSEYa6xvL+SwFfRh0hAJ9ieMzFZ48Os0TR0/y/46e5MmjJ3ny6DSlcuW0/TYN9HHecD9bhnPs2rKZrcO5cLmfrcP9nDfcz+bBrMJZuiqTTrFpIMWmdX5ouDuz1Ron5xY4MVvlxNwCJ8OgbwT+4nJT0+BzU3OLy2e7HpNJ2eIHwGghy+bBLJsHc8FjKMf4YJbxodziukJOUdWKDftbOjlX5cmj02FoT4fBfZLnT84v7jOYy7Br6yBv3LOVXVuH2L11kAuLBbYM5+jvi8l3eZEOMDPy2Qz5bIatw/1rfn3j4v3UbJXji9eIKovB31h3fLZKabrCU8fK/PPTJSZnqsseb6AvzeahptAfDEJ/y3A/20cH2FHMs21kYMP/v9xQgV6t1fkvf3uAH/x8kmen5hbXD/Sl2bV1kNfsHmf31kF2bR3iJVuHOH9Tv74WipwDM1u8rnPByEDLr6vW6pTKFY6dnOeF6XlemK4EP5uWD5dm+OEzk0yUK2d0ENgylGNHMR+E/Gh+Mey3jw5wwcgAfQn/xryhAv3nEzN87bHneNXFY/yHX7uQ3VuG2L11iO2jA6Q28AVEkbjoS6fYGjZbrqZWd54/OceRyVkOl2ZO+/nIzyf52mPPnXYdIGVw3nA/24t5dozmuXAsz7/evonLt48wWsh28rS6ZkMFeqMd/Levvpirdi17ww8R6RHplHH+pgHO3zTAFTuLZ2xfqNV5bmqOw5NByB9phP7kDA/+9AXu++HcYg3/wrE8l+8Y4bLtI1z+ohH2nD/ck803GyzQg/bxYkI+jUVkZZl0ih3FPDuK+WW3T88v8NiR4zx6eIoDhyf5/lMlvnLgWSAYPPbS84eDgN8xwmU7Rnjx5kLsv8lvqECfCGvoY4VcxCURkagN5jK86uLNvOrizYvrfjk1x4HDxzlw+DiPHj7OfT84wucfCu74NtSfWQz4V1w4ymt3j8cu4DdUoJemg0AfLXSuH7CI9K7zNvVzzabzuObl5wFBO/1Pj01z4JnjHDhynAPPHOcvvvNTanXns++9gtddsiXiEp9uQwX6RLnCUC4TDO4QEVlFOmXs3hp0nnjHFTsAOFya4apPfotnp2YjLt2Zkt2HZ4nJmQrFQbWfi8i52zIcNNlOLhlsGAcbKtBL5YouiIrIuuQyaQZzmcVrcnGyoQJ9YrrCmAJdRNapWMieMR1IHGyoQFcNXUTaQYEeMXenVK4kZkSYiERnrJBlYlqBHpnp+QUqtbqaXERk3VRDj1jjl1/UoCIRWafiYBDoHuW9EJexYQL91ChR1dBFZH3GClkqtTrT8wtRF+U0GybQG6NEdVFURNZrNB/kSNyaXTZOoJcV6CLSHmODCvRIlWbCJheNFBWRdWpci1OgR6RUrtDflyKf3VDT14hIBzSuxcVttOiGCfRglKh6uIjI+jWablVDj0ipPK9pc0WkLfLZNLlMSoEelWDYv2roIrJ+ZhbL0aItBbqZXWNmT5jZITO7bZntm8zsq2b2qJkdNLMb21/U9Zkoa2IuEWmfYHDRfNTFOM2qgW5maeAO4FpgD3CDme1ZstvvAj9x98uAq4E/NbNYpacm5hKRdioWcj3Z5HIlcMjdn3L3CnAvcN2SfRwYMjMDBoESEJshVHPVGjOVmgJdRNpmrJDtyV4u24DDTctHwnXNbgdeCjwL/Aj4gLvXlx7IzG4ys/1mtv/YsWPnWOS107B/EWm30Xz8JuhqJdCXu6310hlp3gQcAC4ALgduN7PhM17kfre773X3vePj42ss6rmb1ChREWmzscEsM5Uac9Va1EVZ1EqgHwF2NC1vJ6iJN7sRuM8Dh4CngUvaU8T1W6yha5SoiLRJHPuitxLoDwO7zOyi8ELn9cD9S/Z5Bng9gJltBV4CPNXOgq5H40p0Y0IdEZH1imOgrzoO3t0XzOwW4AEgDdzj7gfN7OZw+13Ax4DPmdmPCJpobnX3FzpY7jVp9BXVSFERaZc4Dv9vaWITd98H7Fuy7q6m588Cb2xv0dqnVK6QSRnDA5rHRUTa41QNPT590TfESNHGvUSDXpUiIuvX+MYfp9GiGyLQNUpURNpteCBDJmWxakPfEIGuUaIi0m5mxmjMbhatQBcROUfFfLxGi26YQFeTi4i0W7GQXRy4GAeJD/Rqrc7UbFVT54pI2wUzLirQu2ZypjHsXze3EJH2itsEXYkP9NLiPC6qoYtIexULWaZmq1RrZ8xFGInkB/q0JuYSkc5oXJtrtARELfGBrom5RKRTGt/849KOnvhAL2nqXBHpkMXh/zEZLZr4QJ8oVzDTTIsi0n6Nb/5xuTCa+EAvlecZGegjndI8LiLSXo2KoppcumSyXFVzi4h0xGg+6A6tGnqXTJTnNQ+6iHREJp1iJN8Xm9GiiQ/0YOpcDSoSkc4oxmiCrg0R6BpUJCKdEowWjcdNLhId6PW6MzlT1cRcItIxqqF3ydRslVrddVFURDqmWMgp0LtBo0RFpNPGClkmZ6rU6x51UZId6BolKiKdVixkqdWdqdlq1EVJeqAHFyoU6CLSKY18iUNf9EQH+mKTi3q5iEiHLM7nokDvrEZnf/VDF5FOUaB3yUS5wmAuQy6TjrooIpJQjU4XCvQOCwYVqf1cRDrnVA09+sFFCnQRkXXIZdIM5jK6KNppE9MVjRIVkY6Ly2jRRAe6augi0g0K9A5z9yDQNUpURDpsrJBlIga3oUtsoE/PL1Cp1dXkIiIdpxp6h50a9q9BRSLSWY1Ad492PpfEB7pq6CLSacVClkqtzvT8QqTlaCnQzewaM3vCzA6Z2W0r7HO1mR0ws4Nm9p32FnPtSoujRBXoItJZjc4Xk+VoJ+haNdDNLA3cAVwL7AFuMLM9S/YZAe4EftPdXwa8vf1FXZsJ1dBFpEsao0WjvnNRKzX0K4FD7v6Uu1eAe4HrluzzTuA+d38GwN2fb28x105T54pItzSu1UV9YbSVQN8GHG5aPhKua7YbGDWzb5vZI2b2nuUOZGY3mdl+M9t/7Nixcytxi0rlCrlMinxW87iISGeNxWQK3VYC3ZZZt/RSbgZ4BfDvgDcB/83Mdp/xIve73X2vu+8dHx9fc2HXojFK1Gy54ouItE9cZlzMtLDPEWBH0/J24Nll9nnB3ctA2cy+C1wGPNmWUp6DUnleg4pEpCvy2TS5TCryQG+lhv4wsMvMLjKzLHA9cP+Sfb4CXGVmGTPLA68EHm9vUdcmGPavPugi0nlmFovRoqvW0N19wcxuAR4A0sA97n7QzG4Ot9/l7o+b2TeAx4A68Bl3/3EnC76aiXKFF48PRlkEEdlARgvZyKfQbaXJBXffB+xbsu6uJcufAj7VvqKtz6Qm5hKRLorD8P9EjhSdq9YoV2oKdBHpmrFCltKMAr3t1AddRLqtWMhRirgNXYEuItIGY4NZypUac9VaZGVIZKBr2L+IdFsc+qInMtAbV5pVQxeRblGgd0ijL+iY+qGLSJfEYfh/IgO9VK6QSRnDAy31yhQRWbdTNfTo+qInNtBHNY+LiHRRI9CjHC2a2EDXBVER6abh/j7SKVMberuVyhVG8wp0EemeVMoYzWeZjHBwUWIDXTMtiki3RT1BVyIDfUJNLiISgajnc0lcoFdrdaZmq+qDLiJdVxxUoLdVo/1KNXQR6baxQlb90Nvp1DwuGlQkIt1VLGSZmq1SrdUjef/kBfq0JuYSkWg0Wgai6umSuEBfnJhLvVxEpMtGI57PJXGB3vhFqh+6iHTb4vD/iLouJjjQ+yIuiYhsNI0JAaO6MJrIQB/J95FJJ+7URCTmimpDb6+Sbg4tIhFptAxENVo0cYE+UZ5XH3QRiUQmnWIk36eLou2iGrqIRCnK4f8JDXQNKhKRaASjRaO5yUWiAr1edyZnqmpyEZHIqIbeJlOzVWp1V5OLiERGgd4mE2UN+xeRaBULWSZnqtTr3vX3TlSgN/p+KtBFJCrFQo5a3ZmarXb9vRMV6BOamEtEIta4hleKYHBRogK9pIm5RCRixQgn6EpYoAddhVRDF5GoNPInitGiiQr0iXKFwVyGXCYddVFEZINqtBDEtoZuZteY2RNmdsjMbjvLfleYWc3M3ta+IrZOo0RFJGqnmly6P7ho1UA3szRwB3AtsAe4wcz2rLDfJ4AH2l3IVinQRSRquUyawVwmkil0W6mhXwkccven3L0C3Atct8x+vwd8CXi+jeVbk4npikaJikjkohpc1EqgbwMONy0fCdctMrNtwFuBu9pXtLUrlSuLt4ASEYnKaIwD3ZZZt3QI1J8Bt7p77awHMrvJzPab2f5jx461WMTWuDulGdXQRSR6Y4VsbHu5HAF2NC1vB55dss9e4F4z+xnwNuBOM3vL0gO5+93uvtfd946Pj59biVdQrtSoLNTVhi4ikYuqySXTwj4PA7vM7CLgF8D1wDubd3D3ixrPzexzwNfc/cvtK+bqSholKiIxMVbIUpqp4O6YLdfI0Rmr1tDdfQG4haD3yuPA37n7QTO72cxu7nQBW9WYf1ijREUkasVClspCnXLlrK3QbddKDR133wfsW7Ju2Qug7v7e9Rdr7UqLMy3q5hYiEq3FvujTwWDHbknMSNFGn09dFBWRqDVaCrp956LEBHpJc6GLSEw0Wgq6fWE0UYGey6TIZzWPi4hEq9FS0O3RookJ9InpYNh/N68oi4gsZzSiKXQTE+iTM5rHRUTioZBNk82kFOjnakITc4lITJhZJKNFExPopfK8eriISGwEN4tWoJ+T0nRFfdBFJDaKhawuip6LuWqNcqWmUaIiEhtjhWzXb3KRiEBXH3QRiZtiIbc4x1S3KNBFRDpgbDBLuVJjrtq9+VwSEega9i8icVOMoC96IgK90U6luxWJSFyM5hXo56TR11M1dBGJi1MTdCnQ12RypkI6ZQz390VdFBERoLnJpXs9XRIR6KVyhdF8llRK87iISDwsTtDVxZ4uiQj0iWndHFpE4mW4v490yro6WjQRgV7SPC4iEjOplDGa7+7NopMT6BolKiIx0+0JuhIR6BNlNbmISPwUC6qhr0m1VmdqtqomFxGJneKgAn1NGhccFOgiEjfFfHdnXOz5QNc8LiISV8VClqnZKtVavSvvp0AXEemQxmjRbnVdTEygj+nmFiISM92eoCsxga4auojEjQJ9jRp9PEfzmsdFROKl0XKgQG9RqVxhJN9HJt3zpyIiCaMa+hpp2L+IxFWj5aBbo0V7PtAnyvMU8wp0EYmfTDrFSL5PNfRWqYYuInHWzeH/iQj0MU3MJSIxFYwW7c5NLno60Ot1Z3JG87iISHzFroZuZteY2RNmdsjMbltm+7vM7LHw8aCZXdb+op7pxFyVWt0palCRiMTUWBcn6Fo10M0sDdwBXAvsAW4wsz1LdnsaeK27Xwp8DLi73QVdzkRZN4cWkXgrFrJMzlSp173j79VKDf1K4JC7P+XuFeBe4LrmHdz9QXefDBcfAra3t5jL0yhREYm7YiFHre6cmKt2/L1aCfRtwOGm5SPhupW8D/j6chvM7CYz229m+48dO9Z6KVfQ6NupQBeRuFq8WXQXml1aCXRbZt2y3x3M7HUEgX7rctvd/W533+vue8fHx1sv5QoWJ+ZSLxcRialujhbNtLDPEWBH0/J24NmlO5nZpcBngGvdfaI9xTu7UtgVaFQDi0QkphqB3o3Roq3U0B8GdpnZRWaWBa4H7m/ewcxeBNwHvNvdn2x/MZc3Ua5QyKbp70t36y1FRNak0YIQixq6uy+Y2S3AA0AauMfdD5rZzeH2u4CPAGPAnWYGsODueztX7ECpXKGo5hYRibFGC0KpC4OLWmlywd33AfuWrLur6fn7gfe3t2irC4b9qw+6iMRXf1+aQjYdm4uisVUqV9QHXURir9ilwUU9H+jqsigicVcs5BToZ+PuTKiGLiI9YKxL87n0bKCXKzUqC3XV0EUk9ro1QVfPBnpJo0RFpEeMFbJMlCu4d3Y+l54N9Mb8wgp0EYm7YiFLZaFOuVLr6Pv0bKBrYi4R6RWLw/87PFq0ZwP91NS56ocuIvG2OPy/w4OLejbQJxs1dI0UFZGY69YEXT0b6KVyhWwmRSGreVxEJN4aLQmdHi3as4He6IMezh0jIhJbxS5N0NWzga5RoiLSKwrZNNlMarGpuFN6NtAnFOgi0iPMbLEveif1bKCXyvMa9i8iPaMbo0V7N9CnK4wq0EWkRxRVQ1/eXLVGuVJTDV1EekYwQZf6oZ/h1ChRDSoSkd4wWshqpOhyNOxfRHrNWCFLuVJjrtq5+Vx6OtDHNEpURHpEo0WhkxdGezrQVUMXkV7RjeH/PRnopybmUqCLSG9otCh0sqdLTwZ6qTxPOmUM9/dFXRQRkZY0auidHC3ao4FeYTSfJZXSPC4i0hvGCqqhL2tiukKxoNq5iPSO4f4+0inraF/0ngx0TcwlIr0mlTJG850d/t+zga47FYlIrxkrZJno4OCingx0zbQoIr1otNCnGnqzhVqdqdmqAl1Ees5YIadAbzY5UwU0SlREek+nZ1zsuUDXKFER6VXFQpap2SrVWr0jx++5QJ8Iu/wo0EWk1zRaFo6HLQ3t1nOBvjgxl3q5iEiP6fR8Lj0X6K+8aIzPvvcKdhQHoi6KiMiaFBdHi3ZmcFFLgW5m15jZE2Z2yMxuW2a7mdmnw+2PmdmvtL+ogfGhHK+7ZAv5bKZTbyEi0hFjHZ5Cd9VAN7M0cAdwLbAHuMHM9izZ7VpgV/i4CfiLNpdTRKTnxaHJ5UrgkLs/5e4V4F7guiX7XAf8lQceAkbM7Pw2l1VEpKeN5IM5qDo1WrSVQN8GHG5aPhKuW+s+mNlNZrbfzPYfO3ZsrWUVEelpfekUv3nZBVy0udCR47fSEL3cHLV+Dvvg7ncDdwPs3bv3jO0iIkn36Rv+TceO3UoN/Qiwo2l5O/DsOewjIiId1EqgPwzsMrOLzCwLXA/cv2Sf+4H3hL1dfhWYcvfn2lxWERE5i1WbXNx9wcxuAR4A0sA97n7QzG4Ot98F7APeDBwCZoAbO1dkERFZTkudud19H0FoN6+7q+m5A7/b3qKJiMha9NxIURERWZ4CXUQkIRToIiIJoUAXEUkIC65nRvDGZseAn5/jyzcDL7SxOL1A57wx6Jw3hvWc84XuPr7chsgCfT3MbL+77426HN2kc94YdM4bQ6fOWU0uIiIJoUAXEUmIXg30u6MuQAR0zhuDznlj6Mg592QbuoiInKlXa+giIrKEAl1EJCFiHehxujl1t7Rwzu8Kz/UxM3vQzC6LopzttNo5N+13hZnVzOxt3SxfJ7RyzmZ2tZkdMLODZvadbpex3Vr4295kZl81s0fDc+7pWVvN7B4ze97MfrzC9vbnl7vH8kEwVe9PgRcDWeBRYM+Sfd4MfJ3gjkm/Cnw/6nJ34ZxfBYyGz6/dCOfctN8/EMz6+baoy92Ff+cR4CfAi8LlLVGXuwvn/IfAJ8Ln40AJyEZd9nWc82uAXwF+vML2tudXnGvoG/Hm1Kues7s/6O6T4eJDBHeH6mWt/DsD/B7wJeD5bhauQ1o553cC97n7MwDu3uvn3co5OzBkZgYMEgT6QneL2T7u/l2Cc1hJ2/MrzoHetptT95C1ns/7CD7he9mq52xm24C3AneRDK38O+8GRs3s22b2iJm9p2ul64xWzvl24KUEt6/8EfABd693p3iRaHt+tXSDi4i07ebUPaTl8zGz1xEE+qs7WqLOa+Wc/wy41d1rQeWt57VyzhngFcDrgQHgn8zsIXd/stOF65BWzvlNwAHg14GLgW+a2T+6+4kOly0qbc+vOAf6Rrw5dUvnY2aXAp8BrnX3iS6VrVNaOee9wL1hmG8G3mxmC+7+5a6UsP1a/dt+wd3LQNnMvgtcBvRqoLdyzjcCH/eggfmQmT0NXAL8c3eK2HVtz684N7lsxJtTr3rOZvYi4D7g3T1cW2u26jm7+0XuvtPddwJfBH6nh8McWvvb/gpwlZllzCwPvBJ4vMvlbKdWzvkZgm8kmNlW4CXAU10tZXe1Pb9iW0P3DXhz6hbP+SPAGHBnWGNd8B6eqa7Fc06UVs7Z3R83s28AjwF14DPuvmz3t17Q4r/zx4DPmdmPCJojbnX3np1W18z+Brga2GxmR4CPAn3QufzS0H8RkYSIc5OLiIisgQJdRCQhFOgiIgmhQBcRSQgFuohIQijQRUQSQoEuIpIQ/x99AnvSYNSKewAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    640\u001b[0m             im, l, b, trans = self.make_image(\n\u001b[1;32m--> 641\u001b[1;33m                 renderer, renderer.get_image_magnification())\n\u001b[0m\u001b[0;32m    642\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mmake_image\u001b[1;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[0;32m    926\u001b[0m         return self._make_image(self._A, bbox, transformed_bbox, clip,\n\u001b[1;32m--> 927\u001b[1;33m                                 magnification, unsampled=unsampled)\n\u001b[0m\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_make_image\u001b[1;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[0;32m    435\u001b[0m                 \u001b[1;31m# Always copy, and don't allow array subtypes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m                 \u001b[0mA_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaled_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m                 \u001b[1;31m# clip scaled data around norm if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d6a26d7d37b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 plt.savefig(f'{save_path}/{idx}-mdls-{mdlsstr}-cons-{CONSENSUS}-thr-{threshstr}-tta-{len(TTAS)}-dice-{int(dice*100000)}.jpeg', transparent=True, bbox_inches = 'tight',\n\u001b[0;32m     68\u001b[0m                                 facecolor = 'k',pad_inches = 0)\n\u001b[1;32m---> 69\u001b[1;33m                 \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mmsk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsk_p\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \"\"\"\n\u001b[0;32m    353\u001b[0m     \u001b[0m_warn_if_gui_out_of_main_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_backend_mod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     40\u001b[0m             display(\n\u001b[0;32m     41\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                 \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             )\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m             \u001b[0mformat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[1;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;31m# FIXME: log the exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;31m# Finally look for special method names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(fig)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'png'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'retina'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'png2x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2228\u001b[0m                        else suppress())\n\u001b[0;32m   2229\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2230\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2232\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2736\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2737\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[1;32m-> 2738\u001b[1;33m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[0;32m   2739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2740\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0msfig\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubfigs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\_api\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[0;32m    429\u001b[0m                          \u001b[1;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m                 **kwargs)\n\u001b[1;32m--> 431\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, inframe)\u001b[0m\n\u001b[0;32m   2923\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2924\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2925\u001b[1;33m         \u001b[0mmimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2927\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'axes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_rasterized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not KAGGLE:\n",
    "    dices = []\n",
    "    PLOT = True\n",
    "    for i in df_sub.index:\n",
    "        if not TEST:\n",
    "            mdlsstr = \"\"\n",
    "            for VER in VERS:\n",
    "                    mdlsstr += f\"{VER}-\"\n",
    "            threshstr = \"\"\n",
    "            for THRESH in THRESHOLD:\n",
    "                 threshstr += f\"{int(THRESH*100)}-\"\n",
    "            df_masks = pd.read_csv(f\"{DATA_PATH}/train.csv\").set_index(\"id\")\n",
    "            idx = df_sub.iloc[i].id\n",
    "            img = tiff.imread(os.path.join(SUB_PATH, idx + \".tiff\"))\n",
    "            print(\"*\" * 20)\n",
    "            print(idx)\n",
    "            print(img.shape)\n",
    "            if len(img.shape) == 5: img = img.squeeze()\n",
    "            if img.shape[0] == 3: img = np.transpose(img.squeeze(), (1, 2, 0))\n",
    "            msk_p = enc2mask([df_sub.iloc[i].predicted], (img.shape[1], img.shape[0]))\n",
    "            msk = enc2mask([df_masks.loc[idx, \"encoding\"]], (img.shape[1], img.shape[0]))\n",
    "            print(img.shape)\n",
    "            print(msk_p.shape)\n",
    "            print(msk.shape)\n",
    "            dice = get_dice(msk_p, msk)\n",
    "            print(f\"dice_coef: {dice}\")\n",
    "            dices.append([dice, msk_p.shape[0]* msk_p.shape[1]])\n",
    "            \n",
    "            if PLOT:\n",
    "                #plt.figure(figsize = (16, 16))\n",
    "                #plt.imshow(img)\n",
    "                #plt.imshow(msk, alpha = 0.3)\n",
    "                #plt.title(idx)\n",
    "                #plt.show()\n",
    "\n",
    "                #plt.figure(figsize = (16, 16))\n",
    "                #plt.figure(figsize = (16, 16))\n",
    "                #plt.imshow(img)\n",
    "                #plt.imshow(msk_p, alpha = 0.3)\n",
    "                #plt.title(idx)\n",
    "                #plt.show()\n",
    "                if PLT_RAW:\n",
    "                    for VER in VERS:\n",
    "                        mask_lrg = complete_results[i][VER]\n",
    "                        plt.figure(figsize = (16,16))\n",
    "                        plt.imshow(msk, cmap = \"BuPu\")\n",
    "                        plt.imshow(mask_lrg, alpha = 0.4)\n",
    "                        plt.title(f\"model: {VER}\")\n",
    "                        plt.show()\n",
    "                        \n",
    "                        thresholds,dices1, n_max = get_best_th_dice(msk, mask_lrg, n=21, plot = False)\n",
    "                        plt.plot(thresholds, dices1)\n",
    "                        plt.title(f\"th: {thresholds[n_max]:.3f} dice: {dices1[n_max]:.5f}\")\n",
    "                        plt.show()\n",
    "                        del mask_lrg, dices1; gc.collect()\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                plt.figure(figsize = (16, 16))\n",
    "                plt.imshow(msk, alpha = 1, cmap = \"BuPu\")\n",
    "                plt.imshow(msk_p, alpha = 0.4)\n",
    "                plt.title(idx)\n",
    "                if len(VERS) == 1:\n",
    "                    save_path = PAR_DICT[VERS[0]][\"MDL_PATH\"]\n",
    "                else:\n",
    "                    save_path = MDLS_PATH\n",
    "                plt.savefig(f'{save_path}/{idx}-mdls-{mdlsstr}-cons-{CONSENSUS}-thr-{threshstr}-tta-{len(TTAS)}-dice-{int(dice*100000)}.jpeg', transparent=True, bbox_inches = 'tight',\n",
    "                                facecolor = 'k',pad_inches = 0)\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "                del msk, idx, img, msk_p; gc.collect()\n",
    "        else:\n",
    "            idx = df_sub.iloc[0].id\n",
    "            img = tiff.imread(os.path.join(SUB_PATH, idx + \".tiff\"))\n",
    "            if len(img.shape) == 5: img = np.transpose(img.squeeze(), (1, 2, 0))\n",
    "            msk_p = enc2mask([df_sub.iloc[0].predicted], (img.shape[1], img.shape[0]))\n",
    "            print(img.shape)\n",
    "            print(msk_p.shape)\n",
    "            plt.figure(figsize = (16, 16))\n",
    "            plt.imshow(img)\n",
    "            plt.imshow(msk_p, alpha = 0.4)\n",
    "            plt.title(idx)\n",
    "            plt.show()\n",
    "    if not TEST:\n",
    "        coef = 0\n",
    "        total = 0\n",
    "        for dice in dices:\n",
    "            coef += dice[0] * dice[1]\n",
    "            total += dice[1]\n",
    "        print(f\"average dice_coef:{coef / total * 0.967}\")\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"time elapsed: {elapsed_time // 60:.0f} min, {elapsed_time % 60:.0f} sec\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afe47d78",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (16, 16))\n",
    "plt.imshow(msk, cmap = \"Reds\")\n",
    "plt.imshow(mask_lrg, cmap = \"Greens\", alpha = 0.4)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
