{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f45d0dd8",
   "metadata": {},
   "source": [
    "%env SM_FRAMEWORK=tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab8e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "system = os.name\n",
    "if system == 'posix':\n",
    "    KAGGLE = True\n",
    "else:\n",
    "    KAGGLE = False\n",
    "print(os.name)\n",
    "\n",
    "if KAGGLE:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpu_devices:\n",
    "    for gpu_device in gpu_devices:\n",
    "        print(\"device available:\", gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a9078",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KAGGLE:\n",
    "    !pip install ../input/keras-applications/Keras_Applications-1.0.8/ -f ./ --no-index\n",
    "    !pip install ../input/image-classifiers/image_classifiers-1.0.0/ -f ./ --no-index\n",
    "    !pip install ../input/efficientnet-1-0-0/efficientnet-1.0.0/ -f ./ --no-index\n",
    "    !pip install ../input/segmentationmodels/ -f ./ --no-index    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cc2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import shutil\n",
    "import numba\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tifffile as tiff\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import *\n",
    "import segmentation_models as sm\n",
    "from segmentation_models import Unet, FPN, Linknet\n",
    "from segmentation_models.losses import bce_jaccard_loss\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "print('tensorflow version:', tf.__version__)\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    for gpu_device in gpu_devices:\n",
    "        print('device available:', gpu_device)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ff4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KAGGLE:\n",
    "    res = pd.read_csv(\"../models/results.csv\", index_col = 0)\n",
    "else: res = 0\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd003a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False\n",
    "PLT_RAW = True\n",
    "if KAGGLE:\n",
    "    TEST = True\n",
    "    PLT_RAW = False\n",
    "\n",
    "VERS = [106]\n",
    "THRESHOLD = [0.5]\n",
    "WEIGHTS = [1]\n",
    "CONSENSUS = 0.3\n",
    "USE_FOLDS = [[0]]\n",
    "DATA_PATH = f\"../input/hubmap-kidney-segmentation\"\n",
    "if KAGGLE:\n",
    "    MDLS_PATH = \"../input/kidneymodel\"\n",
    "else:\n",
    "    MDLS_PATH = \"../models\"\n",
    "\n",
    "PAR_DICT = {}\n",
    "\n",
    "for VER in VERS:\n",
    "    MDL_PATH = f\"{MDLS_PATH}/models_v{VER:03}\"\n",
    "    PAR_DICT[VER] = {\"MDL_PATH\": MDL_PATH}\n",
    "SUB_PATH = f\"{DATA_PATH}/test\" if TEST else f\"{DATA_PATH}/train\"\n",
    "IDNT = rasterio.Affine(1, 0, 0, 0, 1, 0)\n",
    "EXPAND = 4\n",
    "MIN_OVERLAP = 256\n",
    "STRATEGY = tf.distribute.get_strategy()\n",
    "TTAS = [0]\n",
    "\n",
    "VOTERS = 1\n",
    "TARGET_IMG = 'afa5e80ztu98.tiff'\n",
    "start_time = time.time()\n",
    "Y_SHFT = -40\n",
    "X_SHFT = -24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b4fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for VER in VERS:\n",
    "    with open(f\"{PAR_DICT[VER]['MDL_PATH']}/params.json\") as file:\n",
    "        PARAMS = json.load(file)\n",
    "        PAR_DICT[VER][\"PARAMS\"] = PARAMS\n",
    "    print(f\"loaded params: {PARAMS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8864a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc2mask(encs, shape):\n",
    "    img = np.zeros(shape[0] * shape[1], dtype = np.uint8)\n",
    "    for m, enc in enumerate(encs):\n",
    "        if isinstance(enc, np.float) and np.isnan(enc): continue\n",
    "        s = enc.split()\n",
    "        for i in range(len(s) // 2):\n",
    "            start = int(s[2 * i]) - 1\n",
    "            length = int(s[2 * i + 1])\n",
    "            img[start : start + length] = 1 + m\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def rle_encode_less_memory(img):\n",
    "    pixels = img.T.flatten()\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return \" \".join(str(x) for x in runs)\n",
    "\n",
    "def global_shift_mask(maskpred1, y_shift, x_shift):\n",
    "    \"\"\"\n",
    "    applies a global shift to a mask by padding\n",
    "    one side and cropping from the other\n",
    "    \"\"\"\n",
    "    if y_shift < 0 and x_shift >= 0:\n",
    "        maskpred2 = np.pad(maskpred1, [(0,abs(y_shift)), (abs(x_shift), 0)], mode = \"constant\", constant_values=0)\n",
    "        maskpred3 = maskpred2[abs(y_shift):, :maskpred1.shape[1]]\n",
    "    elif y_shift >= 0 and x_shift < 0:\n",
    "        maskpred2 = np.pad(maskpred1, [(abs(y_shift),0), (0, abs(x_shift))], mode = \"constant\", constant_values=0)\n",
    "        maskpred3 = maskpred2[:maskpred1.shape[0], abs(x_shift):]\n",
    "    elif y_shift >= 0 and x_shift >= 0:\n",
    "        maskpred2 = np.pad(maskpred1, [(abs(y_shift),0), (abs(x_shift), 0)], mode = \"constant\", constant_values=0)\n",
    "        maskpred3 = maskpred2[:maskpred1.shape[0], :maskpred1.shape[1]]\n",
    "    elif y_shift < 0 and x_shift < 0:\n",
    "        maskpred2 = np.pad(maskpred1, [(0, abs(y_shift)), (0, abs(x_shift))], mode = \"constant\", constant_values=0)\n",
    "        maskpred3 = maskpred2[abs(y_shift):, abs(x_shift):]\n",
    "    return maskpred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth = 1):\n",
    "    return (1 - dice_coef(y_true, y_pred, smooth))\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return params[\"bce_weight\"] * binary_crossentropy(y_true, y_pred) + \\\n",
    "        (1 - params[\"bce_weight\"]) * dice_loss(y_true, y_pred)\n",
    "\n",
    "def get_model(backbone, input_shape, loss_type = \"bce_dice\",\n",
    "              umodel = \"unet\", classes = 1, lr = 0.001):\n",
    "    if backbone == \"efficientnetb0\":\n",
    "        weights = f\"{MDLS_PATH}/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\"\n",
    "\n",
    "    elif backbone == \"efficientnetb1\":\n",
    "        weights = f\"{MDLS_PATH}/efficientnet-b1_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\"\n",
    "        \n",
    "    elif backbone == \"efficientnetb2\":\n",
    "        weights = f\"{MDLS_PATH}/efficientnet-b2_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\"\n",
    "        \n",
    "    elif backbone == \"efficientnetb7\":\n",
    "        weights = f\"{MDLS_PATH}/efficientnet-b7_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\"\n",
    "        \n",
    "    elif backbone == \"inceptionv3\":\n",
    "        weights = f\"{MDLS_PATH}/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "        \n",
    "    elif backbone == \"resnext50\":\n",
    "        weights = f\"{MDLS_PATH}/resnext50_imagenet_1000_no_top.h5\"\n",
    "    \n",
    "    elif backbone == \"resnet50\":\n",
    "        weights = f\"{MDLS_PATH}/resnet50_imagenet_1000_no_top.h5\"\n",
    "    \n",
    "    elif backbone == \"seresnet50\":\n",
    "        weights = f\"{MDLS_PATH}/seresnet50_imagenet_1000_no_top.h5\"\n",
    "        \n",
    "    elif backbone == \"densenet201\":\n",
    "        weights = f\"{MDLS_PATH}/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "        \n",
    "    elif backbone == \"resnext101\":\n",
    "        weights = f\"{MDLS_PATH}/resnext101_imagenet_1000_no_top.h5\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        raise AttributeError(\"backbone unknown\")\n",
    "    if not KAGGLE:\n",
    "        weights = \"imagenet\"\n",
    "    with STRATEGY.scope():\n",
    "        if loss_type == \"bce_dice\":\n",
    "            loss = bce_dice_loss\n",
    "            \n",
    "        elif loss_type == \"bce_jaccard_loss\":\n",
    "            loss = bce_jaccard_loss\n",
    "            \n",
    "        else:\n",
    "            raise AttributeError(\"loss mode parameter error\")\n",
    "        if umodel == \"unet\":\n",
    "            model = Unet(backbone_name = backbone, encoder_weights = weights,\n",
    "                         input_shape = input_shape,\n",
    "                         classes = classes, activation = \"sigmoid\")\n",
    "        elif umodel == \"fpn\":\n",
    "            model = FPN(backbone_name = backbone, encoder_weights = weights,\n",
    "                        input_shape = input_shape,\n",
    "                        classes = classes, activation = \"sigmoid\")\n",
    "            \n",
    "        elif umodel == \"link\":\n",
    "            model = Linknet(backbone_name = backbone, encoder_weights = weights,\n",
    "                            input_shape = input_shape,\n",
    "                            classes = classes, activation = \"sigmoid\")\n",
    "            \n",
    "        else:\n",
    "            raise AttributeError(\"umodel mode parameter error\")\n",
    "        model.compile(\n",
    "            optimizer = tfa.optimizers.Lookahead(\n",
    "                tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "            ),\n",
    "            loss = loss,\n",
    "            metrics = [dice_coef]\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861ccf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(shape, window = 256, min_overlap = 32):\n",
    "    x, y = shape\n",
    "    nx = x // (window - min_overlap) + 1\n",
    "    x1 = np.linspace(0, x, num = nx, endpoint = False, dtype = np.int64)\n",
    "    x1[-1] = x - window\n",
    "    x2 = (x1 + window).clip(0, x)\n",
    "    ny = y // (window - min_overlap) + 1\n",
    "    y1 = np.linspace(0, y, num = ny, endpoint = False, dtype = np.int64)\n",
    "    y1[-1] = y - window\n",
    "    y2 = (y1 + window).clip(0, y)\n",
    "    slices = np.zeros((nx, ny, 4), dtype = np.int64)\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            slices[i, j] = x1[i], x2[i], y1[j], y2[j]\n",
    "    return slices.reshape(nx * ny, 4)\n",
    "\n",
    "def flip(img, axis = 0):\n",
    "    if axis == 1:\n",
    "        return img[::-1, :, ]\n",
    "    elif axis == 2:\n",
    "        return img[:, ::-1, ]\n",
    "    elif axis == 3:\n",
    "        return img[::-1, ::-1, ]\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d746b4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_img(im):\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "    im = im * (255 / im.max())\n",
    "    im[im > 255] = 255\n",
    "    im = np.round(im).astype(np.uint8)\n",
    "    return im\n",
    "\n",
    "def triple_dims(im):\n",
    "    im = np.transpose(np.array([im,im,im]), (1, 2, 0))\n",
    "    return im\n",
    "\n",
    "subsets = [[0],[1],[2],[0,1],[0,2],[1,2],[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa14589",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = [x for x in os.listdir(SUB_PATH) if \".tiff\" in x]\n",
    "if not TEST:\n",
    "    img_files = img_files[:2]\n",
    "    #import random\n",
    "    #imgs_files = random.shuffle(img_files)\n",
    "print(f\"images idxs: {img_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6926ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_unique(ar):\n",
    "    uniques = np.unique(ar)\n",
    "    print(uniques)\n",
    "    for unique in uniques:\n",
    "        print(f\"{(pred == unique).sum() / (pred.shape[0] * pred.shape[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb1858a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subm = {}\n",
    "models = []\n",
    "VER_FOLDS = []\n",
    "THRESH_FOLDS = []\n",
    "WEIGHTS_FOLDS = []\n",
    "if PLT_RAW:\n",
    "    complete_results = []\n",
    "tile_size = int(PARAMS[\"img_size\"] * EXPAND)\n",
    "for i, VER in enumerate(VERS):\n",
    "    PARAMS = PAR_DICT[VER][\"PARAMS\"]\n",
    "    MDL_PATH = PAR_DICT[VER][\"MDL_PATH\"]\n",
    "    for use_fold in USE_FOLDS[i]:\n",
    "        fold_path = (f\"{MDL_PATH}/model_{use_fold}.hdf5\")\n",
    "        checkpoint_path = fold_path\n",
    "        model = get_model(\n",
    "            PARAMS[\"backbone\"],\n",
    "            input_shape = (tile_size, tile_size, 3),\n",
    "            loss_type = PARAMS[\"loss\"],\n",
    "            umodel = PARAMS[\"umodel\"]\n",
    "        )\n",
    "        model.load_weights(checkpoint_path)\n",
    "        models.append(model)\n",
    "        VER_FOLDS.append(VER)\n",
    "        THRESH_FOLDS.append(THRESHOLD[i])\n",
    "        WEIGHTS_FOLDS.append(WEIGHTS[i])\n",
    "        print(\"model loaded:\", checkpoint_path)\n",
    "\n",
    "for i_img, img_file in enumerate(img_files):\n",
    "    print(\"-\" * 20, img_file, \"-\" * 20)\n",
    "    img_data = rasterio.open(os.path.join(SUB_PATH, img_file), transform=IDNT)\n",
    "    print(\"img shape: \", img_data.shape)\n",
    "    if img_data.count != 3:\n",
    "        print(\"img file with subdatasets as channels\")\n",
    "        layers = [rasterio.open(subd) for subd in img_data.subdatasets]\n",
    "    img_preds = np.zeros(img_data.shape, dtype=np.uint8)\n",
    "    if PLT_RAW:\n",
    "        img_preds_mdls_raw = {}\n",
    "        for VER in VERS:\n",
    "            img_preds_mdls_raw[VER] = np.zeros(img_data.shape, dtype = np.float32)\n",
    "    \n",
    "    tile_resized = int(tile_size * PARAMS[\"resize\"])\n",
    "    slices = make_grid(\n",
    "        img_data.shape,\n",
    "        window = tile_resized,\n",
    "        min_overlap = MIN_OVERLAP\n",
    "    )\n",
    "    \n",
    "    for (x1, x2, y1, y2) in tqdm(slices, desc = f\"{img_file}\"):\n",
    "        if img_data.count == 3: #normal\n",
    "            img = img_data.read(\n",
    "                [1, 2, 3],\n",
    "                window = Window.from_slices((x1, x2), (y1, y2))\n",
    "            )\n",
    "            img = np.moveaxis(img, 0, -1)\n",
    "        else: # with subdatasets/layers\n",
    "            img = np.zeros((tile_resized, tile_resized, 3), dtype = np.uint8)\n",
    "            for fl in range(3):\n",
    "                img[:, :, fl] = layers[fl].read(\n",
    "                    window = Window.from_slices((x1, x2), (y1, y2))\n",
    "                )\n",
    "        img = cv2.resize(img, (tile_size, tile_size))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        pred = np.zeros((tile_size, tile_size), dtype = np.float32)\n",
    "        if PLT_RAW:\n",
    "            pred_raw = {}\n",
    "            for VER in VERS:\n",
    "                pred_raw[VER] = np.zeros((tile_size, tile_size), dtype = np.float32)\n",
    "        i = 0\n",
    "        for model1 in models:\n",
    "            VER = VER_FOLDS[i]\n",
    "            img_cust = img\n",
    "            if \"norm\" in PAR_DICT[VER][\"PARAMS\"].keys():\n",
    "                if PAR_DICT[VER][\"PARAMS\"][\"norm\"]:\n",
    "                    img_cust = norm_img(img_cust)\n",
    "                    img_cust = triple_dims(img_cust)        \n",
    "            \n",
    "            for tta_mode in TTAS:\n",
    "                img_aug = flip(img_cust, axis = tta_mode)\n",
    "                img_aug = np.expand_dims(img_aug, 0)\n",
    "                img_aug = img_aug.astype(np.float32) / 255\n",
    "                pred_aug = np.zeros((tile_size, tile_size), dtype = np.float32)\n",
    "                if \"reduce_dims\" in PAR_DICT[VER][\"PARAMS\"].keys():\n",
    "                    if PAR_DICT[VER][\"PARAMS\"][\"reduce_dims\"]:\n",
    "                        im = np.transpose(img_aug[0], (2,0,1))\n",
    "                        for inds in subsets:\n",
    "                            im_red = im.copy()\n",
    "                            for j in inds:\n",
    "                                im_red[j] = 0\n",
    "                            im_red = np.transpose(im_red, (1, 2, 0))\n",
    "                            im_pred = np.expand_dims(im_red, 0)\n",
    "                            prediction = model1.predict(im_pred)\n",
    "                            pred_aug += np.squeeze(prediction > THRESH_FOLDS[i]) / len(models) / 7\n",
    "                    else:\n",
    "                        prediction = model1.predict(img_aug)\n",
    "                        pred_aug += np.squeeze(prediction > THRESH_FOLDS[i]).astype(np.float32) / len(models)\n",
    "                else:\n",
    "                    prediction = model1.predict(img_aug)                    \n",
    "                    pred_aug += np.squeeze(prediction > THRESH_FOLDS[i]) / len(models)\n",
    "                    \n",
    "                pred += flip(pred_aug, axis = tta_mode).astype(np.float32) / len(TTAS) * WEIGHTS_FOLDS[i]\n",
    "                \n",
    "                if PLT_RAW:\n",
    "                    pred_aug_raw = np.zeros((tile_size, tile_size), dtype = np.float32)\n",
    "                    pred_aug_raw += np.squeeze(prediction)\n",
    "                    pred_raw[VER] += flip(pred_aug_raw, axis = tta_mode) / len(TTAS)\n",
    "                \n",
    "            i += 1\n",
    "        pred = cv2.resize(pred, (tile_resized, tile_resized), interpolation = cv2.INTER_NEAREST)\n",
    "        \n",
    "        img_preds[x1:x2, y1:y2] = img_preds[x1:x2, y1:y2] + \\\n",
    "            (pred > (CONSENSUS * sum(WEIGHTS_FOLDS)/len(WEIGHTS_FOLDS))).astype(np.uint8)\n",
    "        if PLT_RAW:\n",
    "            for VER in VERS:\n",
    "                pred_raw[VER] = cv2.resize(pred_raw[VER], (tile_resized, tile_resized))\n",
    "                img_preds_mdls_raw[VER][x1: x2, y1: y2] = pred_raw[VER] /\\\n",
    "                     PAR_DICT[VER][\"PARAMS\"][\"folds\"]\n",
    "    del img, pred, img_aug, pred_aug; gc.collect()\n",
    "    print(\"img max\", np.max(img_preds), \"| voters:\", VOTERS)\n",
    "    if img_file == TARGET_IMG:\n",
    "        print(\"global shift\")\n",
    "        img_preds = (img_preds >= VOTERS).astype(np.uint8)\n",
    "        img_preds = global_shift_mask(img_preds, Y_SHFT, X_SHFT)\n",
    "    else:\n",
    "        img_preds = (img_preds >= VOTERS).astype(np.uint8)\n",
    "    rle_pred = rle_encode_less_memory(img_preds)\n",
    "    subm[i_img] = {\"id\": img_file.replace(\".tiff\", \"\"), \"predicted\": rle_pred}\n",
    "    if PLT_RAW:\n",
    "        #img_preds_mdls_raw[69420] = np.array([69,420])\n",
    "        #df = pd.DataFrame.from_dict(img_preds_mdls_raw, orient = \"index\")\n",
    "        complete_results.append(img_preds_mdls_raw)\n",
    "        #df = df[df.index != 69420]\n",
    "        #df.to_csv(f\"../models/temp/{img_file.replace('.tiff','')}.csv\")\n",
    "        #del df, img_preds_mdls_raw; gc.collect()\n",
    "        del img_preds_mdls_raw; gc.collect()\n",
    "    del img_preds, img_data, rle_pred; gc.collect()\n",
    "\n",
    "del model, models ; gc.collect()\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed9b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(subm).T\n",
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d7ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af988995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_np(pred, true, k = 1):\n",
    "    intersection = np.sum(pred[true == k]) * 2\n",
    "    dice = intersection / (np.sum(pred) + np.sum(true))\n",
    "    return dice\n",
    "\n",
    "def get_dice(mask, mask_lrg, th = 1):\n",
    "    mask_pred = np.squeeze(mask_lrg >= th)\n",
    "    return dice_np(mask, mask_pred)\n",
    "    \n",
    "def get_best_th_dice(mask, mask_lrg, n=20, plot = False):\n",
    "    thresholds = np.linspace(0, 1, n)\n",
    "    dices = [get_dice(mask, mask_lrg, th) for th in thresholds]\n",
    "    n_max = np.argmax(dices)\n",
    "    if plot:\n",
    "        plt.plot(thresholds, dices)\n",
    "        plt.title(f\"th: {thresholds[n_max]:.2f} dice: {dices[n_max]:.2f}\")\n",
    "        plt.show()\n",
    "    return thresholds, dices, n_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8731d616",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not KAGGLE:\n",
    "    dices = []\n",
    "    PLOT = True\n",
    "    for i in df_sub.index:\n",
    "        if not TEST:\n",
    "            mdlsstr = \"\"\n",
    "            for VER in VERS:\n",
    "                    mdlsstr += f\"{VER}-\"\n",
    "            threshstr = \"\"\n",
    "            for THRESH in THRESHOLD:\n",
    "                 threshstr += f\"{int(THRESH*100)}-\"\n",
    "            df_masks = pd.read_csv(f\"{DATA_PATH}/train.csv\").set_index(\"id\")\n",
    "            idx = df_sub.iloc[i].id\n",
    "            img = tiff.imread(os.path.join(SUB_PATH, idx + \".tiff\"))\n",
    "            print(\"*\" * 20)\n",
    "            print(idx)\n",
    "            print(img.shape)\n",
    "            if len(img.shape) == 5: img = img.squeeze()\n",
    "            if img.shape[0] == 3: img = np.transpose(img.squeeze(), (1, 2, 0))\n",
    "            msk_p = enc2mask([df_sub.iloc[i].predicted], (img.shape[1], img.shape[0]))\n",
    "            msk = enc2mask([df_masks.loc[idx, \"encoding\"]], (img.shape[1], img.shape[0]))\n",
    "            print(img.shape)\n",
    "            print(msk_p.shape)\n",
    "            print(msk.shape)\n",
    "            dice = get_dice(msk_p, msk)\n",
    "            print(f\"dice_coef: {dice}\")\n",
    "            dices.append([dice, msk_p.shape[0]* msk_p.shape[1]])\n",
    "            \n",
    "            if PLOT:\n",
    "                #plt.figure(figsize = (16, 16))\n",
    "                #plt.imshow(img)\n",
    "                #plt.imshow(msk, alpha = 0.3)\n",
    "                #plt.title(idx)\n",
    "                #plt.show()\n",
    "\n",
    "                #plt.figure(figsize = (16, 16))\n",
    "                #plt.figure(figsize = (16, 16))\n",
    "                #plt.imshow(img)\n",
    "                #plt.imshow(msk_p, alpha = 0.3)\n",
    "                #plt.title(idx)\n",
    "                #plt.show()\n",
    "                if PLT_RAW:\n",
    "                    for VER in VERS:\n",
    "                        mask_lrg = complete_results[i][VER]\n",
    "                        plt.figure(figsize = (16,16))\n",
    "                        plt.imshow(msk, cmap = \"BuPu\")\n",
    "                        plt.imshow(mask_lrg, alpha = 0.4)\n",
    "                        plt.title(f\"model: {VER}\")\n",
    "                        plt.show()\n",
    "                        \n",
    "                        thresholds,dices1, n_max = get_best_th_dice(msk, mask_lrg, n=21, plot = False)\n",
    "                        plt.plot(thresholds, dices1)\n",
    "                        plt.title(f\"th: {thresholds[n_max]:.3f} dice: {dices1[n_max]:.5f}\")\n",
    "                        plt.show()\n",
    "                        del mask_lrg, dices1; gc.collect()\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                plt.figure(figsize = (16, 16))\n",
    "                plt.imshow(msk, alpha = 1, cmap = \"BuPu\")\n",
    "                plt.imshow(msk_p, alpha = 0.4)\n",
    "                plt.title(idx)\n",
    "                if len(VERS) == 1:\n",
    "                    save_path = PAR_DICT[VERS[0]][\"MDL_PATH\"]\n",
    "                else:\n",
    "                    save_path = MDLS_PATH\n",
    "                plt.savefig(f'{save_path}/{idx}-mdls-{mdlsstr}-cons-{CONSENSUS}-thr-{threshstr}-tta-{len(TTAS)}-dice-{int(dice*100000)}.jpeg', transparent=True, bbox_inches = 'tight',\n",
    "                                facecolor = 'k',pad_inches = 0)\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "                del msk, idx, img, msk_p; gc.collect()\n",
    "        else:\n",
    "            idx = df_sub.iloc[0].id\n",
    "            img = tiff.imread(os.path.join(SUB_PATH, idx + \".tiff\"))\n",
    "            if len(img.shape) == 5: img = np.transpose(img.squeeze(), (1, 2, 0))\n",
    "            msk_p = enc2mask([df_sub.iloc[0].predicted], (img.shape[1], img.shape[0]))\n",
    "            print(img.shape)\n",
    "            print(msk_p.shape)\n",
    "            plt.figure(figsize = (16, 16))\n",
    "            plt.imshow(img)\n",
    "            plt.imshow(msk_p, alpha = 0.4)\n",
    "            plt.title(idx)\n",
    "            plt.show()\n",
    "    if not TEST:\n",
    "        coef = 0\n",
    "        total = 0\n",
    "        for dice in dices:\n",
    "            coef += dice[0] * dice[1]\n",
    "            total += dice[1]\n",
    "        print(f\"average dice_coef:{coef / total * 0.967}\")\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"time elapsed: {elapsed_time // 60:.0f} min, {elapsed_time % 60:.0f} sec\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afe47d78",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (16, 16))\n",
    "plt.imshow(msk, cmap = \"Reds\")\n",
    "plt.imshow(mask_lrg, cmap = \"Greens\", alpha = 0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae29fda4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "571.733px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
